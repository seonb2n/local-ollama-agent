"""
Ollama ÏÑúÎπÑÏä§ - LLM Î™®Îç∏Í≥ºÏùò ÌÜµÏã†ÏùÑ Îã¥Îãπ
"""
import os
import sys
import time

import aiohttp
import logging
from typing import List, Optional, Dict, Any, Tuple
from langchain_community.llms import Ollama
import json
from .context_manager import context_manager
from .dto.self_improvements import ImprovementIteration, ReflectionResult

sys.path.append(os.path.dirname(os.path.dirname(__file__)))
from ..config import settings

logger = logging.getLogger(__name__)


class OllamaService:
    """Ollama LLM ÏÑúÎπÑÏä§ ÌÅ¥ÎûòÏä§"""

    def __init__(self):
        self.base_url = settings.ollama_base_url
        self.default_model = settings.default_model
        self.backup_model = settings.backup_model
        self.llm = None
        self.max_iterations = 3  # ÏµúÎåÄ Í∞úÏÑ† ÌöüÏàò
        self.min_acceptable_score = 9.0  # ÏµúÏÜå ÌóàÏö© Ï†êÏàò
        self.improvement_history: Dict[str, List[ImprovementIteration]] = {}
        self.enable_self_improvement = True

    async def initialize(self):
        """ÏÑúÎπÑÏä§ Ï¥àÍ∏∞Ìôî"""
        try:
            # LangChain Ollama Í∞ùÏ≤¥ ÏÉùÏÑ±
            self.llm = Ollama(
                model=self.default_model,
                base_url=self.base_url
            )

            # Ïó∞Í≤∞ ÌÖåÏä§Ìä∏
            await self.test_connection()
            logger.info(f"‚úÖ Ollama ÏÑúÎπÑÏä§ Ï¥àÍ∏∞Ìôî ÏôÑÎ£å - Î™®Îç∏: {self.default_model}")

        except Exception as e:
            logger.error(f"‚ùå Ollama ÏÑúÎπÑÏä§ Ï¥àÍ∏∞Ìôî Ïã§Ìå®: {e}")
            # Î∞±ÏóÖ Î™®Îç∏Î°ú Ïû¨ÏãúÎèÑ
            try:
                self.llm = Ollama(
                    model=self.backup_model,
                    base_url=self.base_url
                )
                logger.info(f"‚úÖ Î∞±ÏóÖ Î™®Îç∏Î°ú Ï¥àÍ∏∞Ìôî ÏôÑÎ£å - Î™®Îç∏: {self.backup_model}")
            except Exception as backup_error:
                logger.error(f"‚ùå Î∞±ÏóÖ Î™®Îç∏ÎèÑ Ïã§Ìå®: {backup_error}")
                raise

    async def test_connection(self) -> bool:
        """Ollama ÏÑúÎ≤Ñ Ïó∞Í≤∞ ÌÖåÏä§Ìä∏"""
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(f"{self.base_url}/api/tags") as response:
                    if response.status == 200:
                        return True
                    return False
        except Exception as e:
            logger.error(f"Ïó∞Í≤∞ ÌÖåÏä§Ìä∏ Ïã§Ìå®: {e}")
            return False

    async def get_available_models(self) -> List[str]:
        """ÏÇ¨Ïö© Í∞ÄÎä•Ìïú Î™®Îç∏ Î™©Î°ù Ï°∞Ìöå"""
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(f"{self.base_url}/api/tags") as response:
                    if response.status == 200:
                        data = await response.json()
                        return [model['name'] for model in data.get('models', [])]
                    return []
        except Exception as e:
            logger.error(f"Î™®Îç∏ Î™©Î°ù Ï°∞Ìöå Ïã§Ìå®: {e}")
            return []

    async def generate_code_with_context(
            self,
            description: str,
            language: str = "python",
            framework: Optional[str] = None,
            session_id: Optional[str] = None,
            enable_improvement: Optional[bool] = None
    ) -> str:
        """Ïª®ÌÖçÏä§Ìä∏Î•º ÌôúÏö©Ìïú Ïä§ÎßàÌä∏ ÏΩîÎìú ÏÉùÏÑ± (Self-improvement ÌÜµÌï©)"""

        if not self.llm:
            await self.initialize()

        # Self-improvement ÏÇ¨Ïö© Ïó¨Î∂Ä Í≤∞Ï†ï
        use_improvement = enable_improvement if enable_improvement is not None else self.enable_self_improvement

        # ÏÑ∏ÏÖòÎ≥Ñ Í∞úÏÑ† ÌûàÏä§ÌÜ†Î¶¨ Ï¥àÍ∏∞Ìôî
        if session_id and session_id not in self.improvement_history:
            self.improvement_history[session_id] = []

        # 1. Ïª®ÌÖçÏä§Ìä∏ Ï†ïÎ≥¥ ÏàòÏßë
        context_info = ""
        if session_id:
            context_info = context_manager.get_context_for_llm(session_id)

        # 2. ÏöîÏ≤≠ Ïú†Ìòï Î∂ÑÏÑù Î∞è ÌîÑÎ°¨ÌîÑÌä∏ ÏÉùÏÑ±
        enhanced_prompt = self._build_context_aware_prompt(
            description, language, framework, context_info
        )

        try:
            # 3. Ï¥àÍ∏∞ ÏΩîÎìú ÏÉùÏÑ±
            logger.info(f"üöÄ ÏΩîÎìú ÏÉùÏÑ± ÏãúÏûë - Ïñ∏Ïñ¥: {language}, Í∞úÏÑ†Î™®Îìú: {use_improvement}")
            initial_response = self.llm.invoke(enhanced_prompt)

            if not use_improvement:
                # Self-improvement ÎπÑÌôúÏÑ±Ìôî Ïãú Î∞îÎ°ú Î∞òÌôò
                return initial_response

            # 4. Self-improvement ÏàòÌñâ
            final_response, _ = await self._perform_self_improvement_cycle(
                initial_response, description, language, framework, session_id
            )

            return final_response

        except Exception as e:
            logger.error(f"Ïª®ÌÖçÏä§Ìä∏ Í∏∞Î∞ò ÏΩîÎìú ÏÉùÏÑ± Ïã§Ìå®: {e}")
            raise

    def _build_context_aware_prompt(
            self,
            description: str,
            language: str,
            framework: Optional[str],
            context_info: str
    ) -> str:
        """Ïª®ÌÖçÏä§Ìä∏Î•º Í≥†Î†§Ìïú ÌîÑÎ°¨ÌîÑÌä∏ Íµ¨ÏÑ±"""

        is_modification_request = self._is_code_modification_request(description)

        if context_info and is_modification_request:
            # Í∏∞Ï°¥ ÏΩîÎìú ÏàòÏ†ï ÏöîÏ≤≠
            return f"""
Ïù¥Ï†Ñ ÎåÄÌôî Ïª®ÌÖçÏä§Ìä∏:
{context_info}

ÌòÑÏû¨ ÏöîÏ≤≠: {description}

ÏúÑÏùò Ïª®ÌÖçÏä§Ìä∏ÏóêÏÑú Í∞ÄÏû• ÏµúÍ∑ºÏóê ÏÉùÏÑ±Îêú ÏΩîÎìúÎ•º Í∏∞Î∞òÏúºÎ°ú Îã§Ïùå ÏûëÏóÖÏùÑ ÏàòÌñâÌï¥Ï£ºÏÑ∏Ïöî:
- ÏöîÏ≤≠ÏÇ¨Ìï≠: {description}
- Í∏∞Ï°¥ ÏΩîÎìúÏùò Íµ¨Ï°∞ÏôÄ Í∏∞Îä•ÏùÄ Ïú†ÏßÄÌïòÎ©¥ÏÑú ÏöîÏ≤≠Îêú ÏàòÏ†ïÏÇ¨Ìï≠Îßå Ï†ÅÏö©
- ÏôÑÏ†ÑÌïú ÏàòÏ†ïÎêú ÏΩîÎìúÎ•º Ï†úÍ≥µ (Î∂ÄÎ∂Ñ ÏΩîÎìúÍ∞Ä ÏïÑÎãå Ï†ÑÏ≤¥ ÏΩîÎìú)
- Í∏∞Ï°¥ Ïä§ÌÉÄÏùºÍ≥º Ìå®ÌÑ¥ ÏùºÍ¥ÄÏÑ± Ïú†ÏßÄ

ÏàòÏ†ïÎêú ÏôÑÏ†ÑÌïú ÏΩîÎìú:
"""
        elif context_info:
            # Í∏∞Ï°¥ ÌîÑÎ°úÏ†ùÌä∏Ïóê ÏÉà Í∏∞Îä• Ï∂îÍ∞Ä
            base_template = self._get_template_by_language(description, language, framework)
            return f"""
Ïù¥Ï†Ñ ÎåÄÌôî Ïª®ÌÖçÏä§Ìä∏:
{context_info}

ÌòÑÏû¨ ÏöîÏ≤≠: {base_template}

ÏúÑÏùò Ïª®ÌÖçÏä§Ìä∏Î•º Ï∞∏Í≥†ÌïòÏó¨ Îã§Ïùå Ï°∞Í±¥ÏùÑ ÎßåÏ°±Ìï¥Ï£ºÏÑ∏Ïöî:
1. Í∏∞Ï°¥ ÌîÑÎ°úÏ†ùÌä∏ÏôÄ ÏùºÍ¥ÄÏÑ± Ïú†ÏßÄ (Í∞ôÏùÄ Ïñ∏Ïñ¥, Ïä§ÌÉÄÏùº, Ìå®ÌÑ¥)
2. Ïù¥ÎØ∏ ÏÇ¨Ïö© Ï§ëÏù∏ ÎùºÏù¥Î∏åÎü¨Î¶¨ ÌôúÏö©
3. Í∏∞Ï°¥ ÌååÏùºÎì§Í≥º Ìò∏ÌôòÎêòÎäî Íµ¨Ï°∞
4. Ï†êÏßÑÏ†ÅÏù¥Í≥† Î∞úÏ†ÑÏ†ÅÏù∏ ÏΩîÎìú ÏÉùÏÑ±
5. Í∏∞Ï°¥ ÏïÑÌÇ§ÌÖçÏ≤ò Ìå®ÌÑ¥ Ï§ÄÏàò

ÎãµÎ≥Ä:
"""
        else:
            # ÏÉàÎ°úÏö¥ ÌîÑÎ°úÏ†ùÌä∏ ÏãúÏûë
            return self._get_template_by_language(description, language, framework)

    async def _perform_self_improvement_cycle(
            self,
            initial_response: str,
            description: str,
            language: str,
            framework: Optional[str],
            session_id: Optional[str]
    ) -> Tuple[str, List[ImprovementIteration]]:
        """Self-improvement ÏÇ¨Ïù¥ÌÅ¥ ÏàòÌñâ"""

        current_response = initial_response
        iterations = []

        for iteration in range(self.max_iterations):
            logger.info(f"üîÑ Self-improvement Î∞òÎ≥µ {iteration + 1}/{self.max_iterations}")

            # Self-reflection ÏàòÌñâ
            reflection_result = await self.perform_self_reflection(
                current_response, description, language, framework, session_id
            )

            # Ï†êÏàòÍ∞Ä Ï∂©Î∂ÑÌûà ÎÜíÏúºÎ©¥ Ï¢ÖÎ£å
            if reflection_result.score >= self.min_acceptable_score:
                logger.info(f"‚úÖ ÎßåÏ°±Ïä§Îü¨Ïö¥ ÌíàÏßà Îã¨ÏÑ± (Ï†êÏàò: {reflection_result.score})")
                break
            else:
                logger.info(f"‚úÖ ÌòÑÏû¨ ÌíàÏßà (Ï†êÏàò: {reflection_result.score})")

            # Í∞úÏÑ†Îêú ÏùëÎãµ ÏÉùÏÑ±
            improved_response = await self._generate_improved_response(
                current_response, reflection_result, description, language, framework, session_id
            )

            # Î∞òÎ≥µ Í∏∞Î°ù Ï†ÄÏû•
            iteration_record = ImprovementIteration(
                iteration=iteration + 1,
                original_response=current_response,
                reflection_result=reflection_result,
                improved_response=improved_response,
                improvement_reason=f"Ï†êÏàò {reflection_result.score:.1f} - {', '.join(reflection_result.issues[:2])}",
                timestamp=time.time()
            )
            iterations.append(iteration_record)

            # Îã§Ïùå Î∞òÎ≥µÏùÑ ÏúÑÌï¥ ÌòÑÏû¨ ÏùëÎãµ ÏóÖÎç∞Ïù¥Ìä∏
            current_response = improved_response

            logger.info(f"üìà Î∞òÎ≥µ {iteration + 1} ÏôÑÎ£å - Ï†êÏàò: {reflection_result.score:.1f}")

        # ÏÑ∏ÏÖò ÌûàÏä§ÌÜ†Î¶¨Ïóê Ï∂îÍ∞Ä
        if session_id:
            self.improvement_history[session_id].extend(iterations)

        return current_response, iterations

    async def perform_self_reflection(
            self,
            response: str,
            original_request: str,
            language: str,
            framework: Optional[str],
            session_id: Optional[str] = None
    ) -> ReflectionResult:
        """Self-reflectionÏùÑ ÌÜµÌïú ÏùëÎãµ ÌèâÍ∞Ä (Ïª®ÌÖçÏä§Ìä∏ Í≥†Î†§)"""

        # Ïª®ÌÖçÏä§Ìä∏ Ï†ïÎ≥¥ ÏàòÏßë
        context_guidance = ""
        if session_id:
            context_info = context_manager.get_context_for_llm(session_id)
            if context_info:
                context_guidance = f"""
                            **ÌîÑÎ°úÏ†ùÌä∏ Ïª®ÌÖçÏä§Ìä∏:**
                            {context_info}
                            **Ïª®ÌÖçÏä§Ìä∏ ÏùºÍ¥ÄÏÑ± ÌèâÍ∞Ä Ìè¨Ìï®:**
                            - Í∏∞Ï°¥ ÏΩîÎìú Ïä§ÌÉÄÏùºÍ≥ºÏùò ÏùºÏπòÏÑ±
                            - ÏÇ¨Ïö©Îêú ÎùºÏù¥Î∏åÎü¨Î¶¨Ïùò ÏùºÍ¥ÄÏÑ±
                            - ÏïÑÌÇ§ÌÖçÏ≤ò Ìå®ÌÑ¥Ïùò Ïó∞ÏÜçÏÑ±
                            - ÎÑ§Ïù¥Î∞ç Ïª®Î≤§ÏÖòÏùò ÏùºÏπòÏÑ±
                            """

        reflection_prompt = f"""
                        Îã§Ïùå ÏΩîÎìúÎ•º Ï¢ÖÌï©Ï†ÅÏúºÎ°ú ÌèâÍ∞ÄÌï¥Ï£ºÏÑ∏Ïöî:
                        **ÏõêÎ≥∏ ÏöîÏ≤≠:** {original_request}
                        **Ïñ∏Ïñ¥:** {language}
                        **ÌîÑÎ†àÏûÑÏõåÌÅ¨:** {framework or "ÏóÜÏùå"}
                        {context_guidance}
                        **ÏÉùÏÑ±Îêú ÏΩîÎìú:**
                        ```{language}
                        {response}
                        ```
                        Îã§Ïùå Í∏∞Ï§ÄÏúºÎ°ú ÌèâÍ∞ÄÌïòÍ≥† JSON ÌòïÏãùÏúºÎ°ú ÎãµÎ≥ÄÌï¥Ï£ºÏÑ∏Ïöî:
                        {{
                            "score": Ï†êÏàò (0-10, ÏÜåÏàòÏ†ê 1ÏûêÎ¶¨),
                            "code_quality": {{
                                "score": Ï†êÏàò (0-10),
                                "issues": ["Î¨∏Ï†úÏ†ê1", "Î¨∏Ï†úÏ†ê2"],
                                "good_points": ["Ïû•Ï†ê1", "Ïû•Ï†ê2"]
                            }},
                            "completeness": {{
                                "score": Ï†êÏàò (0-10),
                                "missing_features": ["ÎàÑÎùΩÎêú Í∏∞Îä•1", "ÎàÑÎùΩÎêú Í∏∞Îä•2"],
                                "satisfied_requirements": ["ÎßåÏ°±Îêú ÏöîÍµ¨ÏÇ¨Ìï≠1", "ÎßåÏ°±Îêú ÏöîÍµ¨ÏÇ¨Ìï≠2"]
                            }},
                            "context_consistency": {{
                                "score": Ï†êÏàò (0-10),
                                "inconsistencies": ["Î∂àÏùºÏπò ÏÇ¨Ìï≠1", "Î∂àÏùºÏπò ÏÇ¨Ìï≠2"],
                                "good_alignment": ["Ïûò ÎßûÎäî Î∂ÄÎ∂Ñ1", "Ïûò ÎßûÎäî Î∂ÄÎ∂Ñ2"]
                            }},
                            "best_practices": {{
                                "score": Ï†êÏàò (0-10),
                                "violations": ["ÏúÑÎ∞òÏÇ¨Ìï≠1", "ÏúÑÎ∞òÏÇ¨Ìï≠2"],
                                "good_practices": ["Ï¢ãÏùÄ Í¥ÄÎ°Ä1", "Ï¢ãÏùÄ Í¥ÄÎ°Ä2"]
                            }},
                            "error_handling": {{
                                "score": Ï†êÏàò (0-10),
                                "missing_error_handling": ["ÎàÑÎùΩÎêú ÏóêÎü¨ Ï≤òÎ¶¨1", "ÎàÑÎùΩÎêú ÏóêÎü¨ Ï≤òÎ¶¨2"],
                                "good_error_handling": ["Ï¢ãÏùÄ ÏóêÎü¨ Ï≤òÎ¶¨1", "Ï¢ãÏùÄ ÏóêÎü¨ Ï≤òÎ¶¨2"]
                            }},
                            "overall_issues": ["Ï†ÑÏ≤¥Ï†ÅÏù∏ Î¨∏Ï†úÏ†ê1", "Ï†ÑÏ≤¥Ï†ÅÏù∏ Î¨∏Ï†úÏ†ê2", "Ï†ÑÏ≤¥Ï†ÅÏù∏ Î¨∏Ï†úÏ†ê3"],
                            "improvement_suggestions": ["Í∞úÏÑ† Ï†úÏïà1", "Í∞úÏÑ† Ï†úÏïà2", "Í∞úÏÑ† Ï†úÏïà3"],
                            "overall_assessment": "Ï†ÑÏ≤¥Ï†ÅÏù∏ ÌèâÍ∞Ä Î∞è ÏöîÏïΩ"
                        }}
                        ÌèâÍ∞Ä Í∏∞Ï§Ä:
                        - 9-10: Îõ∞Ïñ¥ÎÇ® (production-ready, Ïª®ÌÖçÏä§Ìä∏ ÏôÑÎ≤Ω ÏùºÏπò)
                        - 7-8: Ï¢ãÏùå (minor improvements needed)
                        - 5-6: Î≥¥ÌÜµ (moderate improvements needed)
                        - 3-4: ÎÇòÏÅ® (major improvements needed)
                        - 0-2: Îß§Ïö∞ ÎÇòÏÅ® (complete rewrite needed)
                        """

        try:
            reflection_response = self.llm.invoke(reflection_prompt)

            try:
                reflection_data = json.loads(reflection_response)
            except json.JSONDecodeError:
                reflection_data = self._extract_reflection_from_text(reflection_response)

            issues = reflection_data.get("overall_issues", [])
            suggestions = reflection_data.get("improvement_suggestions", [])

            return ReflectionResult(
                score=float(reflection_data.get("score", 5.0)),
                issues=issues,
                suggestions=suggestions,
                overall_assessment=reflection_data.get("overall_assessment", "ÌèâÍ∞ÄÎ•º ÏôÑÎ£åÌñàÏäµÎãàÎã§.")
            )

        except Exception as e:
            logger.error(f"Self-reflection Ïã§Ìå®: {e}")
            return ReflectionResult(
                score=5.0,
                issues=["ÌèâÍ∞Ä Ï§ë Ïò§Î•ò Î∞úÏÉù"],
                suggestions=["Ïû¨ÌèâÍ∞Ä ÌïÑÏöî"],
                overall_assessment="ÌèâÍ∞ÄÎ•º ÏôÑÎ£åÌïòÏßÄ Î™ªÌñàÏäµÎãàÎã§."
            )

    async def _generate_improved_response(
            self,
            original_response: str,
            reflection_result: ReflectionResult,
            original_request: str,
            language: str,
            framework: Optional[str],
            session_id: Optional[str] = None
    ) -> str:
        """Í∞úÏÑ†Îêú ÏùëÎãµ ÏÉùÏÑ± (Ïª®ÌÖçÏä§Ìä∏ ÌôúÏö©)"""

        # Ïª®ÌÖçÏä§Ìä∏ Ï†ïÎ≥¥ ÏàòÏßë
        context_guidance = ""
        if session_id:
            context_info = context_manager.get_context_for_llm(session_id)
            if context_info:
                context_guidance = f"""
**Ïù¥Ï†Ñ ÎåÄÌôî Ïª®ÌÖçÏä§Ìä∏:**
{context_info}

**Ïª®ÌÖçÏä§Ìä∏ ÌôúÏö© ÏßÄÏπ®:**
- Í∏∞Ï°¥ ÌîÑÎ°úÏ†ùÌä∏ÏôÄÏùò ÏùºÍ¥ÄÏÑ± Ïú†ÏßÄ (ÏΩîÎî© Ïä§ÌÉÄÏùº, ÎÑ§Ïù¥Î∞ç Ïª®Î≤§ÏÖò, ÏïÑÌÇ§ÌÖçÏ≤ò Ìå®ÌÑ¥)
- Ïù¥ÎØ∏ ÏÇ¨Ïö©Îêú ÎùºÏù¥Î∏åÎü¨Î¶¨ÏôÄ ÎîîÌéúÎçòÏãú Ïû¨ÌôúÏö©
- Í∏∞Ï°¥ ÏΩîÎìúÏôÄÏùò Ìò∏ÌôòÏÑ± Î≥¥Ïû•
- ÌîÑÎ°úÏ†ùÌä∏ Ï†ÑÏ≤¥ Íµ¨Ï°∞Ïóê ÎßûÎäî Í∞úÏÑ†
- Í∏∞Ï°¥ ÏÑ§Ï†ïÍ∞íÏù¥ÎÇò ÌôòÍ≤ΩÎ≥ÄÏàò ÌôúÏö©
"""

        # Í∞úÏÑ† ÌûàÏä§ÌÜ†Î¶¨ÏóêÏÑú ÌïôÏäµ
        improvement_history_guidance = ""
        if session_id and session_id in self.improvement_history:
            recent_iterations = self.improvement_history[session_id][-3:]
            if recent_iterations:
                common_patterns = self._analyze_improvement_patterns(recent_iterations)
                improvement_history_guidance = f"""
**Ïù¥Ï†Ñ Í∞úÏÑ† Ìå®ÌÑ¥ Î∂ÑÏÑù:**
{common_patterns}

**Î∞òÎ≥µÎêòÎäî Ïù¥Ïäà Î∞©ÏßÄ:**
- Ïù¥Ï†ÑÏóê Î∞úÍ≤¨Îêú Í≥µÌÜµ Î¨∏Ï†úÏ†êÎì§ÏùÑ ÎØ∏Î¶¨ Í≥†Î†§
- ÏÑ±Í≥µÏ†ÅÏù¥ÏóàÎçò Í∞úÏÑ† Î∞©Ìñ•ÏÑ± Ï∞∏Í≥†
- Î∞òÎ≥µÎêòÎäî Ïã§Ïàò Ìå®ÌÑ¥ ÌöåÌîº
"""

        improvement_prompt = f"""
Îã§Ïùå ÏΩîÎìúÎ•º Ï¢ÖÌï©Ï†ÅÏúºÎ°ú Í∞úÏÑ†Ìï¥Ï£ºÏÑ∏Ïöî:

**ÏõêÎ≥∏ ÏöîÏ≤≠:** {original_request}
**Ïñ∏Ïñ¥:** {language}
**ÌîÑÎ†àÏûÑÏõåÌÅ¨:** {framework or "ÏóÜÏùå"}

{context_guidance}

{improvement_history_guidance}

**ÌòÑÏû¨ ÏΩîÎìú:**
```{language}
{original_response}
```

**Î∞úÍ≤¨Îêú Î¨∏Ï†úÏ†êÎì§:**
{chr(10).join(f"- {issue}" for issue in reflection_result.issues)}

**Í∞úÏÑ† Ï†úÏïàÏÇ¨Ìï≠:**
{chr(10).join(f"- {suggestion}" for suggestion in reflection_result.suggestions)}

**ÌòÑÏû¨ Ï†êÏàò:** {reflection_result.score}/10
**Î™©Ìëú Ï†êÏàò:** 8.0+ (production-ready ÏàòÏ§Ä)

ÏúÑÏùò Î™®Îì† Ï†ïÎ≥¥Î•º Ï¢ÖÌï©ÌïòÏó¨ Í∞úÏÑ†Îêú ÏôÑÏ†ÑÌïú ÏΩîÎìúÎ•º ÏûëÏÑ±Ìï¥Ï£ºÏÑ∏Ïöî.

Í∞úÏÑ† Ïãú Ïö∞ÏÑ†ÏàúÏúÑ:
1. **Ïª®ÌÖçÏä§Ìä∏ ÏùºÍ¥ÄÏÑ±**: Í∏∞Ï°¥ ÌîÑÎ°úÏ†ùÌä∏ÏôÄÏùò Ïó∞Í≥ÑÏÑ± Î∞è Ìò∏ÌôòÏÑ±
2. **Î¨∏Ï†úÏ†ê Ìï¥Í≤∞**: Î∞úÍ≤¨Îêú Î™®Îì† Ïù¥Ïäà ÏôÑÏ†Ñ Ìï¥Í≤∞
3. **ÌíàÏßà Ìñ•ÏÉÅ**: ÏΩîÎìú Íµ¨Ï°∞, Í∞ÄÎèÖÏÑ±, Ïú†ÏßÄÎ≥¥ÏàòÏÑ± Í∞úÏÑ†
4. **ÏóêÎü¨ Ï≤òÎ¶¨**: Í≤¨Í≥†Ìïú ÏòàÏô∏ Ï≤òÎ¶¨ Î∞è ÏóêÎü¨ Î≥µÍµ¨
5. **Î≤†Ïä§Ìä∏ ÌîÑÎûôÌã∞Ïä§**: ÏóÖÍ≥Ñ ÌëúÏ§Ä Î∞è Í∂åÏû•ÏÇ¨Ìï≠ Ï†ÅÏö©
6. **ÏôÑÏ†ÑÏÑ±**: Ïã§Ï†ú ÏÇ¨Ïö© Í∞ÄÎä•Ìïú ÏàòÏ§ÄÏùò Íµ¨ÌòÑ

Í∞úÏÑ†Îêú ÏôÑÏ†ÑÌïú ÏΩîÎìúÎßå Ï∂úÎ†•ÌïòÍ≥† Ï∂îÍ∞Ä ÏÑ§Î™ÖÏùÄ ÏµúÏÜåÌôîÌï¥Ï£ºÏÑ∏Ïöî.
        """

        try:
            improved_response = self.llm.invoke(improvement_prompt)
            return improved_response

        except Exception as e:
            logger.error(f"Í∞úÏÑ†Îêú ÏùëÎãµ ÏÉùÏÑ± Ïã§Ìå®: {e}")
            return original_response

    def _analyze_improvement_patterns(self, recent_iterations: List[ImprovementIteration]) -> str:
        """ÏµúÍ∑º Í∞úÏÑ† Î∞òÎ≥µÏóêÏÑú Ìå®ÌÑ¥ Î∂ÑÏÑù"""
        if not recent_iterations:
            return "Í∞úÏÑ† ÌûàÏä§ÌÜ†Î¶¨ ÏóÜÏùå"

        all_issues = []
        all_suggestions = []

        for iteration in recent_iterations:
            all_issues.extend(iteration.reflection_result.issues)
            all_suggestions.extend(iteration.reflection_result.suggestions)

        issue_counts = {}
        suggestion_counts = {}

        for issue in all_issues:
            issue_counts[issue] = issue_counts.get(issue, 0) + 1

        for suggestion in all_suggestions:
            suggestion_counts[suggestion] = suggestion_counts.get(suggestion, 0) + 1

        top_issues = sorted(issue_counts.items(), key=lambda x: x[1], reverse=True)[:3]
        top_suggestions = sorted(suggestion_counts.items(), key=lambda x: x[1], reverse=True)[:3]

        pattern_analysis = "Î∞òÎ≥µÎêòÎäî Ï£ºÏöî Ïù¥Ïäà:\n"
        for issue, count in top_issues:
            pattern_analysis += f"- {issue} (Î∞úÏÉù {count}Ìöå)\n"

        pattern_analysis += "\nÏûêÏ£º Ï†úÏïàÎêòÎäî Í∞úÏÑ†ÏÇ¨Ìï≠:\n"
        for suggestion, count in top_suggestions:
            pattern_analysis += f"- {suggestion} (Ï†úÏïà {count}Ìöå)\n"

        return pattern_analysis

    def _extract_reflection_from_text(self, text: str) -> Dict[str, Any]:
        """ÌÖçÏä§Ìä∏ÏóêÏÑú reflection Ï†ïÎ≥¥ Ï∂îÏ∂ú (JSON ÌååÏã± Ïã§Ìå® Ïãú Î∞±ÏóÖ)"""
        import re

        score_match = re.search(r'score["\s:]*(\d+\.?\d*)', text, re.IGNORECASE)
        score = float(score_match.group(1)) if score_match else 5.0

        return {
            "score": score,
            "overall_issues": ["ÌÖçÏä§Ìä∏ ÌååÏã±ÏúºÎ°ú Ï∂îÏ∂úÎêú Ïù¥Ïäà"],
            "improvement_suggestions": ["ÏÉÅÏÑ∏ Î∂ÑÏÑùÏùÑ ÏúÑÌï¥ JSON ÌòïÏãù ÏùëÎãµ ÌïÑÏöî"],
            "overall_assessment": "Î∂ÄÎ∂ÑÏ†Å ÌèâÍ∞Ä ÏôÑÎ£å"
        }

    def _is_code_modification_request(self, description: str) -> bool:
        """ÏΩîÎìú ÏàòÏ†ï ÏöîÏ≤≠Ïù∏ÏßÄ ÌåêÎã®"""
        modification_keywords = [
            "ÏàòÏ†ï", "Î≥ÄÍ≤Ω", "Î∞îÍøî", "Ï†úÍ±∞", "ÏÇ≠Ï†ú", "Ï∂îÍ∞ÄÌï¥Ï§ò", "Í≥†Ï≥ê",
            "Ï£ºÏÑù Ï†úÍ±∞", "Ï£ºÏÑù Ï∂îÍ∞Ä", "Î¶¨Ìå©ÌÜ†ÎßÅ", "ÏµúÏ†ÅÌôî",
            "Ïù¥ ÏΩîÎìúÎ•º", "Î∞©Í∏à ÎßåÎì†", "ÎÑàÍ∞Ä ÎßåÎì†", "Í∏∞Ï°¥ ÏΩîÎìú",
            "Ïù¥ Ïï±Ïóê", "Ïù¥ ÌîÑÎ°úÍ∑∏Îû®Ïóê", "ÏúÑ ÏΩîÎìúÏóê"
        ]

        description_lower = description.lower()
        return any(keyword in description_lower for keyword in modification_keywords)

    def _get_template_by_language(self, description: str, language: str, framework: Optional[str]) -> str:
        """Ïñ∏Ïñ¥Î≥Ñ ÌÖúÌîåÎ¶ø ÏÑ†ÌÉù"""
        templates = {
            "python": self._get_python_template(description, framework),
            "javascript": self._get_javascript_template(description, framework),
            "java": self._get_java_template(description, framework)
        }

        return templates.get(language, templates["python"])

    def _get_python_template(self, description: str, framework: Optional[str]) -> str:
        """Python ÏΩîÎìú ÏÉùÏÑ± ÌÖúÌîåÎ¶ø"""
        framework_info = ""
        if framework:
            framework_info = f"ÌîÑÎ†àÏûÑÏõåÌÅ¨Îäî {framework}ÏùÑ ÏÇ¨Ïö©Ìï¥Ï£ºÏÑ∏Ïöî."

        return f"""
                Îã§Ïùå ÏöîÍµ¨ÏÇ¨Ìï≠Ïóê ÎßûÎäî ÏôÑÏ†ÑÌïú Python ÏΩîÎìúÎ•º ÏûëÏÑ±Ìï¥Ï£ºÏÑ∏Ïöî:

                ÏöîÍµ¨ÏÇ¨Ìï≠: {description}
                {framework_info}
    
                Îã§Ïùå Ï°∞Í±¥ÏùÑ ÎßåÏ°±Ìï¥Ïïº Ìï©ÎãàÎã§:
                1. Î™®Îì† ÌïÑÏöîÌïú import Î¨∏ Ìè¨Ìï®
                2. Ïã§Ìñâ Í∞ÄÎä•Ìïú ÏôÑÏ†ÑÌïú ÏΩîÎìú
                3. ÏóêÎü¨ Ï≤òÎ¶¨ Ìè¨Ìï® (try-except)
                4. ÏÉÅÏÑ∏Ìïú Ï£ºÏÑùÏúºÎ°ú ÏΩîÎìú ÏÑ§Î™Ö
                5. Î©îÏù∏ Ïã§Ìñâ Î∂ÄÎ∂Ñ Ìè¨Ìï® (if __name__ == "__main__":)
                6. ÏÇ¨Ïö©Ïûê ÏπúÌôîÏ†ÅÏù∏ Ï∂úÎ†• Î©îÏãúÏßÄ

                ÏΩîÎìúÎßå Ï∂úÎ†•ÌïòÍ≥† Îã§Î•∏ ÏÑ§Î™ÖÏùÄ ÏµúÏÜåÌôîÌï¥Ï£ºÏÑ∏Ïöî.
                """

    def _get_javascript_template(self, description: str, framework: Optional[str]) -> str:
        """JavaScript ÏΩîÎìú ÏÉùÏÑ± ÌÖúÌîåÎ¶ø"""
        framework_info = ""
        if framework:
            framework_info = f"ÌîÑÎ†àÏûÑÏõåÌÅ¨Îäî {framework}ÏùÑ ÏÇ¨Ïö©Ìï¥Ï£ºÏÑ∏Ïöî."

        return f"""
            Îã§Ïùå ÏöîÍµ¨ÏÇ¨Ìï≠Ïóê ÎßûÎäî ÏôÑÏ†ÑÌïú JavaScript ÏΩîÎìúÎ•º ÏûëÏÑ±Ìï¥Ï£ºÏÑ∏Ïöî:

            ÏöîÍµ¨ÏÇ¨Ìï≠: {description}
            {framework_info}

            Îã§Ïùå Ï°∞Í±¥ÏùÑ ÎßåÏ°±Ìï¥Ïïº Ìï©ÎãàÎã§:
            1. Î™®Îì† ÌïÑÏöîÌïú import/require Î¨∏ Ìè¨Ìï®
            2. Ïã§Ìñâ Í∞ÄÎä•Ìïú ÏôÑÏ†ÑÌïú ÏΩîÎìú
            3. ÏóêÎü¨ Ï≤òÎ¶¨ Ìè¨Ìï® (try-catch)
            4. ÏÉÅÏÑ∏Ìïú Ï£ºÏÑùÏúºÎ°ú ÏΩîÎìú ÏÑ§Î™Ö
            5. ÏÇ¨Ïö©Ïûê ÏπúÌôîÏ†ÅÏù∏ Ï∂úÎ†•

            ÏΩîÎìúÎßå Ï∂úÎ†•ÌïòÍ≥† Îã§Î•∏ ÏÑ§Î™ÖÏùÄ ÏµúÏÜåÌôîÌï¥Ï£ºÏÑ∏Ïöî.
            """

    def _get_java_template(self, description: str, framework: Optional[str]) -> str:
        """Java ÏΩîÎìú ÏÉùÏÑ± ÌÖúÌîåÎ¶ø"""
        framework_info = ""
        if framework:
            framework_info = f"ÌîÑÎ†àÏûÑÏõåÌÅ¨Îäî {framework}ÏùÑ ÏÇ¨Ïö©Ìï¥Ï£ºÏÑ∏Ïöî."

        return f"""
            Îã§Ïùå ÏöîÍµ¨ÏÇ¨Ìï≠Ïóê ÎßûÎäî ÏôÑÏ†ÑÌïú Java ÏΩîÎìúÎ•º ÏûëÏÑ±Ìï¥Ï£ºÏÑ∏Ïöî:

            ÏöîÍµ¨ÏÇ¨Ìï≠: {description}
            {framework_info}

            Îã§Ïùå Ï°∞Í±¥ÏùÑ ÎßåÏ°±Ìï¥Ïïº Ìï©ÎãàÎã§:
            1. ÏôÑÏ†ÑÌïú ÌÅ¥ÎûòÏä§ Íµ¨Ï°∞
            2. Î™®Îì† ÌïÑÏöîÌïú import Î¨∏ Ìè¨Ìï®
            3. Ïã§Ìñâ Í∞ÄÎä•Ìïú main Î©îÏÜåÎìú
            4. ÏòàÏô∏ Ï≤òÎ¶¨ Ìè¨Ìï®
            5. ÏÉÅÏÑ∏Ìïú Ï£ºÏÑùÏúºÎ°ú ÏΩîÎìú ÏÑ§Î™Ö

            ÏΩîÎìúÎßå Ï∂úÎ†•ÌïòÍ≥† Îã§Î•∏ ÏÑ§Î™ÖÏùÄ ÏµúÏÜåÌôîÌï¥Ï£ºÏÑ∏Ïöî.
            """

    # Ìé∏Ïùò Î©îÏÑúÎìúÎì§
    def set_improvement_enabled(self, enabled: bool):
        """Self-improvement Í∏∞Îä• ÌôúÏÑ±Ìôî/ÎπÑÌôúÏÑ±Ìôî"""
        self.enable_self_improvement = enabled
        logger.info(f"Self-improvement Î™®Îìú: {'ÌôúÏÑ±Ìôî' if enabled else 'ÎπÑÌôúÏÑ±Ìôî'}")

    def set_quality_threshold(self, threshold: float):
        """ÌíàÏßà ÏûÑÍ≥ÑÍ∞í ÏÑ§Ï†ï (0-10)"""
        self.min_acceptable_score = max(0.0, min(10.0, threshold))
        logger.info(f"ÌíàÏßà ÏûÑÍ≥ÑÍ∞í ÏÑ§Ï†ï: {self.min_acceptable_score}")

    def set_max_iterations(self, max_iter: int):
        """ÏµúÎåÄ Î∞òÎ≥µ ÌöüÏàò ÏÑ§Ï†ï"""
        self.max_iterations = max(1, min(10, max_iter))
        logger.info(f"ÏµúÎåÄ Î∞òÎ≥µ ÌöüÏàò ÏÑ§Ï†ï: {self.max_iterations}")

    def get_improvement_history(self, session_id: str) -> List[ImprovementIteration]:
        """ÏÑ∏ÏÖòÎ≥Ñ Í∞úÏÑ† ÌûàÏä§ÌÜ†Î¶¨ Ï°∞Ìöå"""
        return self.improvement_history.get(session_id, [])

    def get_improvement_statistics(self, session_id: str) -> Dict[str, Any]:
        """Í∞úÏÑ† ÌÜµÍ≥Ñ Ï†ïÎ≥¥"""
        history = self.get_improvement_history(session_id)
        if not history:
            return {}

        total_iterations = len(history)
        avg_initial_score = sum(iter.reflection_result.score for iter in history) / total_iterations
        common_issues = {}

        for iteration in history:
            for issue in iteration.reflection_result.issues:
                common_issues[issue] = common_issues.get(issue, 0) + 1

        return {
            "total_requests": len(set(iter.timestamp // 3600 for iter in history)),
            "total_iterations": total_iterations,
            "average_initial_score": round(avg_initial_score, 1),
            "most_common_issues": sorted(common_issues.items(), key=lambda x: x[1], reverse=True)[:5],
            "improvement_rate": round((total_iterations - len(history)) / max(total_iterations, 1) * 100, 1)
        }


# Ïã±Í∏ÄÌÜ§ Ïù∏Ïä§ÌÑ¥Ïä§
ollama_service = OllamaService()
