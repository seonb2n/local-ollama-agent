"""
Ollama ÏÑúÎπÑÏä§ - LLM Î™®Îç∏Í≥ºÏùò ÌÜµÏã†ÏùÑ Îã¥Îãπ
"""
import os
import sys
import time

os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'

import aiohttp
import logging
from typing import List, Optional, Dict, Any, Tuple

from dotenv import load_dotenv
from langchain_community.llms import Ollama
import json
from .context_manager import context_manager
from .dto.self_improvements import ImprovementIteration, ReflectionResult
from ..repository.RagIntegration import RAGIntegration

sys.path.append(os.path.dirname(os.path.dirname(__file__)))
from ..config import settings

logger = logging.getLogger(__name__)


class OllamaService:
    """Ollama LLM ÏÑúÎπÑÏä§ ÌÅ¥ÎûòÏä§"""

    def __init__(self):
        self.base_url = settings.ollama_base_url
        self.default_model = settings.default_model
        self.backup_model = settings.backup_model
        self.llm = None
        self.max_iterations = 3  # ÏµúÎåÄ Í∞úÏÑ† ÌöüÏàò
        self.min_acceptable_score = 7.5  # ÏµúÏÜå ÌóàÏö© Ï†êÏàò
        self.improvement_history: Dict[str, List[ImprovementIteration]] = {}
        self.enable_self_improvement = True
        self.enable_web_search = True
        self.web_search_threshold = 0.7  # Ïõπ Í≤ÄÏÉâ ÌïÑÏöîÎèÑ ÏûÑÍ≥ÑÍ∞í
        self.max_search_results = 3

        load_dotenv('.env.local')

        self.google_api_key = os.getenv('GOOGLE_SEARCH_API_KEY')
        self.search_engine_id = os.getenv('GOOGLE_SEARCH_ENGINE_ID')

        self.rag_integration = None
        self.enable_rag = True  # RAG Í∏∞Îä• ÌôúÏÑ±Ìôî Ïó¨Î∂Ä

    async def initialize(self):
        """ÏÑúÎπÑÏä§ Ï¥àÍ∏∞Ìôî"""
        try:
            # LangChain Ollama Í∞ùÏ≤¥ ÏÉùÏÑ±
            self.llm = Ollama(
                model=self.default_model,
                base_url=self.base_url
            )

            if self.enable_rag:
                self.rag_integration = RAGIntegration()
                await self.rag_integration.initialize(self.default_model)
                logger.info("‚úÖ RAG ÏãúÏä§ÌÖú Ï¥àÍ∏∞Ìôî ÏôÑÎ£å")

            # Ïó∞Í≤∞ ÌÖåÏä§Ìä∏
            await self.test_connection()
            logger.info(f"‚úÖ Ollama ÏÑúÎπÑÏä§ Ï¥àÍ∏∞Ìôî ÏôÑÎ£å - Î™®Îç∏: {self.default_model}")

        except Exception as e:
            logger.error(f"‚ùå Ollama ÏÑúÎπÑÏä§ Ï¥àÍ∏∞Ìôî Ïã§Ìå®: {e}")
            # Î∞±ÏóÖ Î™®Îç∏Î°ú Ïû¨ÏãúÎèÑ
            try:
                self.llm = Ollama(
                    model=self.backup_model,
                    base_url=self.base_url
                )
                logger.info(f"‚úÖ Î∞±ÏóÖ Î™®Îç∏Î°ú Ï¥àÍ∏∞Ìôî ÏôÑÎ£å - Î™®Îç∏: {self.backup_model}")
            except Exception as backup_error:
                logger.error(f"‚ùå Î∞±ÏóÖ Î™®Îç∏ÎèÑ Ïã§Ìå®: {backup_error}")
                raise

    async def test_connection(self) -> bool:
        """Ollama ÏÑúÎ≤Ñ Ïó∞Í≤∞ ÌÖåÏä§Ìä∏"""
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(f"{self.base_url}/api/tags") as response:
                    if response.status == 200:
                        return True
                    return False
        except Exception as e:
            logger.error(f"Ïó∞Í≤∞ ÌÖåÏä§Ìä∏ Ïã§Ìå®: {e}")
            return False

    async def get_available_models(self) -> List[str]:
        """ÏÇ¨Ïö© Í∞ÄÎä•Ìïú Î™®Îç∏ Î™©Î°ù Ï°∞Ìöå"""
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(f"{self.base_url}/api/tags") as response:
                    if response.status == 200:
                        data = await response.json()
                        return [model['name'] for model in data.get('models', [])]
                    return []
        except Exception as e:
            logger.error(f"Î™®Îç∏ Î™©Î°ù Ï°∞Ìöå Ïã§Ìå®: {e}")
            return []

    async def generate_code_with_context(
            self,
            description: str,
            language: str = "python",
            framework: Optional[str] = None,
            session_id: Optional[str] = None,
            enable_improvement: Optional[bool] = None
    ) -> str:
        """Ïª®ÌÖçÏä§Ìä∏Î•º ÌôúÏö©Ìïú Ïä§ÎßàÌä∏ ÏΩîÎìú ÏÉùÏÑ± (Self-improvement ÌÜµÌï©)"""

        if not self.llm:
            await self.initialize()

        # Self-improvement ÏÇ¨Ïö© Ïó¨Î∂Ä Í≤∞Ï†ï
        use_improvement = enable_improvement if enable_improvement is not None else self.enable_self_improvement

        # ÏÑ∏ÏÖòÎ≥Ñ Í∞úÏÑ† ÌûàÏä§ÌÜ†Î¶¨ Ï¥àÍ∏∞Ìôî
        if session_id and session_id not in self.improvement_history:
            self.improvement_history[session_id] = []

        # 1. Ïª®ÌÖçÏä§Ìä∏ Ï†ïÎ≥¥ ÏàòÏßë
        context_info = ""
        if session_id:
            context_info = context_manager.get_context_for_llm(session_id)

        # 1-1. RAG Í≤ÄÏÉâ ÏàòÌñâ (Ïõπ Í≤ÄÏÉâÎ≥¥Îã§ Ïö∞ÏÑ†)
        rag_info = ""
        optimized_keyword = self._get_optimized_query(description, language)
        if self.enable_rag and self.rag_integration:
            should_use_rag = await self.rag_integration.should_use_rag(description)
            if should_use_rag:
                logger.info("üîç RAG ÏãúÏä§ÌÖúÏùÑ ÌÜµÌïú ÏßÄÏãù Í≤ÄÏÉâ Ï§ë...")
                try:
                    # RAGÎ°ú Í¥ÄÎ†® Î¨∏ÏÑú Í≤ÄÏÉâ
                    search_results = await self.rag_integration.search_knowledge(optimized_keyword)
                    if search_results:
                        rag_info = f"""
        **Í¥ÄÎ†® Í∏∞Ïà† Î¨∏ÏÑú (RAG Í≤ÄÏÉâ Í≤∞Í≥º):**
        {search_results}
        """
                        logger.info("‚úÖ RAG Í≤ÄÏÉâ ÏôÑÎ£å")
                except Exception as e:
                    logger.error(f"RAG Í≤ÄÏÉâ Ïã§Ìå®: {e}")

            # 1-2. Ïõπ Í≤ÄÏÉâ ÏàòÌñâ (RAG Í≤∞Í≥ºÍ∞Ä ÏóÜÍ±∞ÎÇò Î∂ÄÏ°±Ìïú Í≤ΩÏö∞)
        web_search_info = ""
        if not rag_info and await self._should_perform_web_search(description, language, framework):
            logger.info("üîç Ïõπ Í≤ÄÏÉâ ÏàòÌñâ Ï§ë...")
            web_search_info = await self._perform_web_search(optimized_keyword)
            logger.info("‚úÖ Ïõπ Í≤ÄÏÉâ ÏôÑÎ£å")

        # 2. ÏöîÏ≤≠ Ïú†Ìòï Î∂ÑÏÑù Î∞è ÌîÑÎ°¨ÌîÑÌä∏ ÏÉùÏÑ±
        enhanced_prompt = self._build_context_aware_prompt(
            description, language, framework, context_info, rag_info + web_search_info
        )

        try:
            # 3. Ï¥àÍ∏∞ ÏΩîÎìú ÏÉùÏÑ±
            logger.info(f"üöÄ ÏΩîÎìú ÏÉùÏÑ± ÏãúÏûë - Ïñ∏Ïñ¥: {language}, Í∞úÏÑ†Î™®Îìú: {use_improvement}")
            initial_response = self.llm.invoke(enhanced_prompt)

            if not use_improvement:
                # Self-improvement ÎπÑÌôúÏÑ±Ìôî Ïãú Î∞îÎ°ú Î∞òÌôò
                return initial_response

            # 4. Self-improvement ÏàòÌñâ
            final_response, _ = await self._perform_self_improvement_cycle(
                initial_response, description, language, framework, session_id
            )

            return final_response

        except Exception as e:
            logger.error(f"Ïª®ÌÖçÏä§Ìä∏ Í∏∞Î∞ò ÏΩîÎìú ÏÉùÏÑ± Ïã§Ìå®: {e}")
            raise

    def _build_context_aware_prompt(
            self,
            description: str,
            language: str,
            framework: Optional[str],
            context_info: str,
            web_search_info: str = ""
    ) -> str:
        """Ïª®ÌÖçÏä§Ìä∏Î•º Í≥†Î†§Ìïú ÌîÑÎ°¨ÌîÑÌä∏ Íµ¨ÏÑ±"""

        is_modification_request = self._is_code_modification_request(description)

        # Ïõπ Í≤ÄÏÉâ Ï†ïÎ≥¥ Ï∂îÍ∞Ä
        web_search_section = ""
        if web_search_info:
            web_search_section = f"""
        **ÏµúÏã† Ï†ïÎ≥¥ (Ïõπ Í≤ÄÏÉâ Í≤∞Í≥º):**
        {web_search_info}

        ÏúÑÏùò ÏµúÏã† Ï†ïÎ≥¥Î•º Ï∞∏Í≥†ÌïòÏó¨ ÌòÑÏû¨ ÏÉÅÌô©Ïóê ÎßûÎäî ÏµúÏ†ÅÏùò ÏΩîÎìúÎ•º ÏûëÏÑ±Ìï¥Ï£ºÏÑ∏Ïöî.
        """

        if context_info and is_modification_request:
            # Í∏∞Ï°¥ ÏΩîÎìú ÏàòÏ†ï ÏöîÏ≤≠
            return f"""
Ïù¥Ï†Ñ ÎåÄÌôî Ïª®ÌÖçÏä§Ìä∏:
{context_info}

Ïõπ Í≤ÄÏÉâ Ìï≠Î™©ÏùÑ ÌÜµÌïú ÏµúÏã† Ï†ïÎ≥¥:
{web_search_section}

ÌòÑÏû¨ ÏöîÏ≤≠: {description}

ÏúÑÏùò Ïª®ÌÖçÏä§Ìä∏ÏóêÏÑú Í∞ÄÏû• ÏµúÍ∑ºÏóê ÏÉùÏÑ±Îêú ÏΩîÎìúÎ•º Í∏∞Î∞òÏúºÎ°ú Îã§Ïùå ÏûëÏóÖÏùÑ ÏàòÌñâÌï¥Ï£ºÏÑ∏Ïöî:
- ÏöîÏ≤≠ÏÇ¨Ìï≠: {description}
- Í∏∞Ï°¥ ÏΩîÎìúÏùò Íµ¨Ï°∞ÏôÄ Í∏∞Îä•ÏùÄ Ïú†ÏßÄÌïòÎ©¥ÏÑú ÏöîÏ≤≠Îêú ÏàòÏ†ïÏÇ¨Ìï≠Îßå Ï†ÅÏö©
- ÏôÑÏ†ÑÌïú ÏàòÏ†ïÎêú ÏΩîÎìúÎ•º Ï†úÍ≥µ (Î∂ÄÎ∂Ñ ÏΩîÎìúÍ∞Ä ÏïÑÎãå Ï†ÑÏ≤¥ ÏΩîÎìú)
- Í∏∞Ï°¥ Ïä§ÌÉÄÏùºÍ≥º Ìå®ÌÑ¥ ÏùºÍ¥ÄÏÑ± Ïú†ÏßÄ

ÏàòÏ†ïÎêú ÏôÑÏ†ÑÌïú ÏΩîÎìú:
"""
        elif context_info:
            # Í∏∞Ï°¥ ÌîÑÎ°úÏ†ùÌä∏Ïóê ÏÉà Í∏∞Îä• Ï∂îÍ∞Ä
            base_template = self._get_template_by_language(description, language, framework)
            return f"""
Ïù¥Ï†Ñ ÎåÄÌôî Ïª®ÌÖçÏä§Ìä∏:
{context_info}

ÌòÑÏû¨ ÏöîÏ≤≠: {base_template}

ÏúÑÏùò Ïª®ÌÖçÏä§Ìä∏Î•º Ï∞∏Í≥†ÌïòÏó¨ Îã§Ïùå Ï°∞Í±¥ÏùÑ ÎßåÏ°±Ìï¥Ï£ºÏÑ∏Ïöî:
1. Í∏∞Ï°¥ ÌîÑÎ°úÏ†ùÌä∏ÏôÄ ÏùºÍ¥ÄÏÑ± Ïú†ÏßÄ (Í∞ôÏùÄ Ïñ∏Ïñ¥, Ïä§ÌÉÄÏùº, Ìå®ÌÑ¥)
2. Ïù¥ÎØ∏ ÏÇ¨Ïö© Ï§ëÏù∏ ÎùºÏù¥Î∏åÎü¨Î¶¨ ÌôúÏö©
3. Í∏∞Ï°¥ ÌååÏùºÎì§Í≥º Ìò∏ÌôòÎêòÎäî Íµ¨Ï°∞
4. Ï†êÏßÑÏ†ÅÏù¥Í≥† Î∞úÏ†ÑÏ†ÅÏù∏ ÏΩîÎìú ÏÉùÏÑ±
5. Í∏∞Ï°¥ ÏïÑÌÇ§ÌÖçÏ≤ò Ìå®ÌÑ¥ Ï§ÄÏàò

ÎãµÎ≥Ä:
"""
        else:
            # ÏÉàÎ°úÏö¥ ÌîÑÎ°úÏ†ùÌä∏ ÏãúÏûë
            return self._get_template_by_language(description, language, framework)

    async def _perform_self_improvement_cycle(
            self,
            initial_response: str,
            description: str,
            language: str,
            framework: Optional[str],
            session_id: Optional[str]
    ) -> Tuple[str, List[ImprovementIteration]]:
        """Self-improvement ÏÇ¨Ïù¥ÌÅ¥ ÏàòÌñâ"""

        current_response = initial_response
        iterations = []

        for iteration in range(self.max_iterations):
            logger.info(f"üîÑ Self-improvement Î∞òÎ≥µ {iteration + 1}/{self.max_iterations}")

            # Self-reflection ÏàòÌñâ
            reflection_result = await self.perform_self_reflection(
                current_response, description, language, framework, session_id
            )

            # Ï†êÏàòÍ∞Ä Ï∂©Î∂ÑÌûà ÎÜíÏúºÎ©¥ Ï¢ÖÎ£å
            if reflection_result.score >= self.min_acceptable_score:
                logger.info(f"‚úÖ ÎßåÏ°±Ïä§Îü¨Ïö¥ ÌíàÏßà Îã¨ÏÑ± (Ï†êÏàò: {reflection_result.score})")
                break
            else:
                logger.info(f"‚úÖ ÌòÑÏû¨ ÌíàÏßà (Ï†êÏàò: {reflection_result.score})")

            # Í∞úÏÑ†Îêú ÏùëÎãµ ÏÉùÏÑ±
            improved_response = await self._generate_improved_response(
                current_response, reflection_result, description, language, framework, session_id
            )

            # Î∞òÎ≥µ Í∏∞Î°ù Ï†ÄÏû•
            iteration_record = ImprovementIteration(
                iteration=iteration + 1,
                original_response=current_response,
                reflection_result=reflection_result,
                improved_response=improved_response,
                improvement_reason=f"Ï†êÏàò {reflection_result.score:.1f} - {', '.join(reflection_result.issues[:2])}",
                timestamp=time.time()
            )
            iterations.append(iteration_record)

            # Îã§Ïùå Î∞òÎ≥µÏùÑ ÏúÑÌï¥ ÌòÑÏû¨ ÏùëÎãµ ÏóÖÎç∞Ïù¥Ìä∏
            current_response = improved_response

            logger.info(f"üìà Î∞òÎ≥µ {iteration + 1} ÏôÑÎ£å - Ï†êÏàò: {reflection_result.score:.1f}")

        # ÏÑ∏ÏÖò ÌûàÏä§ÌÜ†Î¶¨Ïóê Ï∂îÍ∞Ä
        if session_id:
            self.improvement_history[session_id].extend(iterations)

        return current_response, iterations

    async def perform_self_reflection(
            self,
            response: str,
            original_request: str,
            language: str,
            framework: Optional[str],
            session_id: Optional[str] = None
    ) -> ReflectionResult:
        """Self-reflectionÏùÑ ÌÜµÌïú ÏùëÎãµ ÌèâÍ∞Ä (Ïª®ÌÖçÏä§Ìä∏ Í≥†Î†§)"""

        # Ïª®ÌÖçÏä§Ìä∏ Ï†ïÎ≥¥ ÏàòÏßë
        context_guidance = ""
        if session_id:
            context_info = context_manager.get_context_for_llm(session_id)
            if context_info:
                context_guidance = f"""
                            **ÌîÑÎ°úÏ†ùÌä∏ Ïª®ÌÖçÏä§Ìä∏:**
                            {context_info}
                            **Ïª®ÌÖçÏä§Ìä∏ ÏùºÍ¥ÄÏÑ± ÌèâÍ∞Ä Ìè¨Ìï®:**
                            - Í∏∞Ï°¥ ÏΩîÎìú Ïä§ÌÉÄÏùºÍ≥ºÏùò ÏùºÏπòÏÑ±
                            - ÏÇ¨Ïö©Îêú ÎùºÏù¥Î∏åÎü¨Î¶¨Ïùò ÏùºÍ¥ÄÏÑ±
                            - ÏïÑÌÇ§ÌÖçÏ≤ò Ìå®ÌÑ¥Ïùò Ïó∞ÏÜçÏÑ±
                            - ÎÑ§Ïù¥Î∞ç Ïª®Î≤§ÏÖòÏùò ÏùºÏπòÏÑ±
                            """

        reflection_prompt = f"""
                        Îã§Ïùå ÏΩîÎìúÎ•º Ï¢ÖÌï©Ï†ÅÏúºÎ°ú ÌèâÍ∞ÄÌï¥Ï£ºÏÑ∏Ïöî:
                        **ÏõêÎ≥∏ ÏöîÏ≤≠:** {original_request}
                        **Ïñ∏Ïñ¥:** {language}
                        **ÌîÑÎ†àÏûÑÏõåÌÅ¨:** {framework or "ÏóÜÏùå"}
                        {context_guidance}
                        **ÏÉùÏÑ±Îêú ÏΩîÎìú:**
                        ```{language}
                        {response}
                        ```
                        Îã§Ïùå Í∏∞Ï§ÄÏúºÎ°ú ÌèâÍ∞ÄÌïòÍ≥† JSON ÌòïÏãùÏúºÎ°ú ÎãµÎ≥ÄÌï¥Ï£ºÏÑ∏Ïöî:
                        {{
                            "score": Ï†êÏàò (0-10, ÏÜåÏàòÏ†ê 1ÏûêÎ¶¨),
                            "code_quality": {{
                                "score": Ï†êÏàò (0-10),
                                "issues": ["Î¨∏Ï†úÏ†ê1", "Î¨∏Ï†úÏ†ê2"],
                                "good_points": ["Ïû•Ï†ê1", "Ïû•Ï†ê2"]
                            }},
                            "completeness": {{
                                "score": Ï†êÏàò (0-10),
                                "missing_features": ["ÎàÑÎùΩÎêú Í∏∞Îä•1", "ÎàÑÎùΩÎêú Í∏∞Îä•2"],
                                "satisfied_requirements": ["ÎßåÏ°±Îêú ÏöîÍµ¨ÏÇ¨Ìï≠1", "ÎßåÏ°±Îêú ÏöîÍµ¨ÏÇ¨Ìï≠2"]
                            }},
                            "context_consistency": {{
                                "score": Ï†êÏàò (0-10),
                                "inconsistencies": ["Î∂àÏùºÏπò ÏÇ¨Ìï≠1", "Î∂àÏùºÏπò ÏÇ¨Ìï≠2"],
                                "good_alignment": ["Ïûò ÎßûÎäî Î∂ÄÎ∂Ñ1", "Ïûò ÎßûÎäî Î∂ÄÎ∂Ñ2"]
                            }},
                            "best_practices": {{
                                "score": Ï†êÏàò (0-10),
                                "violations": ["ÏúÑÎ∞òÏÇ¨Ìï≠1", "ÏúÑÎ∞òÏÇ¨Ìï≠2"],
                                "good_practices": ["Ï¢ãÏùÄ Í¥ÄÎ°Ä1", "Ï¢ãÏùÄ Í¥ÄÎ°Ä2"]
                            }},
                            "error_handling": {{
                                "score": Ï†êÏàò (0-10),
                                "missing_error_handling": ["ÎàÑÎùΩÎêú ÏóêÎü¨ Ï≤òÎ¶¨1", "ÎàÑÎùΩÎêú ÏóêÎü¨ Ï≤òÎ¶¨2"],
                                "good_error_handling": ["Ï¢ãÏùÄ ÏóêÎü¨ Ï≤òÎ¶¨1", "Ï¢ãÏùÄ ÏóêÎü¨ Ï≤òÎ¶¨2"]
                            }},
                            "overall_issues": ["Ï†ÑÏ≤¥Ï†ÅÏù∏ Î¨∏Ï†úÏ†ê1", "Ï†ÑÏ≤¥Ï†ÅÏù∏ Î¨∏Ï†úÏ†ê2", "Ï†ÑÏ≤¥Ï†ÅÏù∏ Î¨∏Ï†úÏ†ê3"],
                            "improvement_suggestions": ["Í∞úÏÑ† Ï†úÏïà1", "Í∞úÏÑ† Ï†úÏïà2", "Í∞úÏÑ† Ï†úÏïà3"],
                            "overall_assessment": "Ï†ÑÏ≤¥Ï†ÅÏù∏ ÌèâÍ∞Ä Î∞è ÏöîÏïΩ"
                        }}
                        ÌèâÍ∞Ä Í∏∞Ï§Ä:
                        - 9-10: Îõ∞Ïñ¥ÎÇ® (production-ready, Ïª®ÌÖçÏä§Ìä∏ ÏôÑÎ≤Ω ÏùºÏπò)
                        - 7-8: Ï¢ãÏùå (minor improvements needed)
                        - 5-6: Î≥¥ÌÜµ (moderate improvements needed)
                        - 3-4: ÎÇòÏÅ® (major improvements needed)
                        - 0-2: Îß§Ïö∞ ÎÇòÏÅ® (complete rewrite needed)
                        """

        try:
            reflection_response = self.llm.invoke(reflection_prompt)

            try:
                reflection_data = json.loads(reflection_response)
            except json.JSONDecodeError:
                reflection_data = self._extract_reflection_from_text(reflection_response)

            issues = reflection_data.get("overall_issues", [])
            suggestions = reflection_data.get("improvement_suggestions", [])

            return ReflectionResult(
                score=float(reflection_data.get("score", 5.0)),
                issues=issues,
                suggestions=suggestions,
                overall_assessment=reflection_data.get("overall_assessment", "ÌèâÍ∞ÄÎ•º ÏôÑÎ£åÌñàÏäµÎãàÎã§.")
            )

        except Exception as e:
            logger.error(f"Self-reflection Ïã§Ìå®: {e}")
            return ReflectionResult(
                score=5.0,
                issues=["ÌèâÍ∞Ä Ï§ë Ïò§Î•ò Î∞úÏÉù"],
                suggestions=["Ïû¨ÌèâÍ∞Ä ÌïÑÏöî"],
                overall_assessment="ÌèâÍ∞ÄÎ•º ÏôÑÎ£åÌïòÏßÄ Î™ªÌñàÏäµÎãàÎã§."
            )

    async def _generate_improved_response(
            self,
            original_response: str,
            reflection_result: ReflectionResult,
            original_request: str,
            language: str,
            framework: Optional[str],
            session_id: Optional[str] = None
    ) -> str:
        """Í∞úÏÑ†Îêú ÏùëÎãµ ÏÉùÏÑ± (Ïª®ÌÖçÏä§Ìä∏ ÌôúÏö©)"""

        # Ïª®ÌÖçÏä§Ìä∏ Ï†ïÎ≥¥ ÏàòÏßë
        context_guidance = ""
        if session_id:
            context_info = context_manager.get_context_for_llm(session_id)
            if context_info:
                context_guidance = f"""
**Ïù¥Ï†Ñ ÎåÄÌôî Ïª®ÌÖçÏä§Ìä∏:**
{context_info}

**Ïª®ÌÖçÏä§Ìä∏ ÌôúÏö© ÏßÄÏπ®:**
- Í∏∞Ï°¥ ÌîÑÎ°úÏ†ùÌä∏ÏôÄÏùò ÏùºÍ¥ÄÏÑ± Ïú†ÏßÄ (ÏΩîÎî© Ïä§ÌÉÄÏùº, ÎÑ§Ïù¥Î∞ç Ïª®Î≤§ÏÖò, ÏïÑÌÇ§ÌÖçÏ≤ò Ìå®ÌÑ¥)
- Ïù¥ÎØ∏ ÏÇ¨Ïö©Îêú ÎùºÏù¥Î∏åÎü¨Î¶¨ÏôÄ ÎîîÌéúÎçòÏãú Ïû¨ÌôúÏö©
- Í∏∞Ï°¥ ÏΩîÎìúÏôÄÏùò Ìò∏ÌôòÏÑ± Î≥¥Ïû•
- ÌîÑÎ°úÏ†ùÌä∏ Ï†ÑÏ≤¥ Íµ¨Ï°∞Ïóê ÎßûÎäî Í∞úÏÑ†
- Í∏∞Ï°¥ ÏÑ§Ï†ïÍ∞íÏù¥ÎÇò ÌôòÍ≤ΩÎ≥ÄÏàò ÌôúÏö©
"""

        # Í∞úÏÑ† ÌûàÏä§ÌÜ†Î¶¨ÏóêÏÑú ÌïôÏäµ
        improvement_history_guidance = ""
        if session_id and session_id in self.improvement_history:
            recent_iterations = self.improvement_history[session_id][-3:]
            if recent_iterations:
                common_patterns = self._analyze_improvement_patterns(recent_iterations)
                improvement_history_guidance = f"""
**Ïù¥Ï†Ñ Í∞úÏÑ† Ìå®ÌÑ¥ Î∂ÑÏÑù:**
{common_patterns}

**Î∞òÎ≥µÎêòÎäî Ïù¥Ïäà Î∞©ÏßÄ:**
- Ïù¥Ï†ÑÏóê Î∞úÍ≤¨Îêú Í≥µÌÜµ Î¨∏Ï†úÏ†êÎì§ÏùÑ ÎØ∏Î¶¨ Í≥†Î†§
- ÏÑ±Í≥µÏ†ÅÏù¥ÏóàÎçò Í∞úÏÑ† Î∞©Ìñ•ÏÑ± Ï∞∏Í≥†
- Î∞òÎ≥µÎêòÎäî Ïã§Ïàò Ìå®ÌÑ¥ ÌöåÌîº
"""

        improvement_prompt = f"""
Îã§Ïùå ÏΩîÎìúÎ•º Ï¢ÖÌï©Ï†ÅÏúºÎ°ú Í∞úÏÑ†Ìï¥Ï£ºÏÑ∏Ïöî:

**ÏõêÎ≥∏ ÏöîÏ≤≠:** {original_request}
**Ïñ∏Ïñ¥:** {language}
**ÌîÑÎ†àÏûÑÏõåÌÅ¨:** {framework or "ÏóÜÏùå"}

{context_guidance}

{improvement_history_guidance}

**ÌòÑÏû¨ ÏΩîÎìú:**
```{language}
{original_response}
```

**Î∞úÍ≤¨Îêú Î¨∏Ï†úÏ†êÎì§:**
{chr(10).join(f"- {issue}" for issue in reflection_result.issues)}

**Í∞úÏÑ† Ï†úÏïàÏÇ¨Ìï≠:**
{chr(10).join(f"- {suggestion}" for suggestion in reflection_result.suggestions)}

**ÌòÑÏû¨ Ï†êÏàò:** {reflection_result.score}/10
**Î™©Ìëú Ï†êÏàò:** 8.0+ (production-ready ÏàòÏ§Ä)

ÏúÑÏùò Î™®Îì† Ï†ïÎ≥¥Î•º Ï¢ÖÌï©ÌïòÏó¨ Í∞úÏÑ†Îêú ÏôÑÏ†ÑÌïú ÏΩîÎìúÎ•º ÏûëÏÑ±Ìï¥Ï£ºÏÑ∏Ïöî.

Í∞úÏÑ† Ïãú Ïö∞ÏÑ†ÏàúÏúÑ:
1. **Ïª®ÌÖçÏä§Ìä∏ ÏùºÍ¥ÄÏÑ±**: Í∏∞Ï°¥ ÌîÑÎ°úÏ†ùÌä∏ÏôÄÏùò Ïó∞Í≥ÑÏÑ± Î∞è Ìò∏ÌôòÏÑ±
2. **Î¨∏Ï†úÏ†ê Ìï¥Í≤∞**: Î∞úÍ≤¨Îêú Î™®Îì† Ïù¥Ïäà ÏôÑÏ†Ñ Ìï¥Í≤∞
3. **ÌíàÏßà Ìñ•ÏÉÅ**: ÏΩîÎìú Íµ¨Ï°∞, Í∞ÄÎèÖÏÑ±, Ïú†ÏßÄÎ≥¥ÏàòÏÑ± Í∞úÏÑ†
4. **ÏóêÎü¨ Ï≤òÎ¶¨**: Í≤¨Í≥†Ìïú ÏòàÏô∏ Ï≤òÎ¶¨ Î∞è ÏóêÎü¨ Î≥µÍµ¨
5. **Î≤†Ïä§Ìä∏ ÌîÑÎûôÌã∞Ïä§**: ÏóÖÍ≥Ñ ÌëúÏ§Ä Î∞è Í∂åÏû•ÏÇ¨Ìï≠ Ï†ÅÏö©
6. **ÏôÑÏ†ÑÏÑ±**: Ïã§Ï†ú ÏÇ¨Ïö© Í∞ÄÎä•Ìïú ÏàòÏ§ÄÏùò Íµ¨ÌòÑ

Í∞úÏÑ†Îêú ÏôÑÏ†ÑÌïú ÏΩîÎìúÎßå Ï∂úÎ†•ÌïòÍ≥† Ï∂îÍ∞Ä ÏÑ§Î™ÖÏùÄ ÏµúÏÜåÌôîÌï¥Ï£ºÏÑ∏Ïöî.
        """

        try:
            improved_response = self.llm.invoke(improvement_prompt)
            return improved_response

        except Exception as e:
            logger.error(f"Í∞úÏÑ†Îêú ÏùëÎãµ ÏÉùÏÑ± Ïã§Ìå®: {e}")
            return original_response

    def _analyze_improvement_patterns(self, recent_iterations: List[ImprovementIteration]) -> str:
        """ÏµúÍ∑º Í∞úÏÑ† Î∞òÎ≥µÏóêÏÑú Ìå®ÌÑ¥ Î∂ÑÏÑù"""
        if not recent_iterations:
            return "Í∞úÏÑ† ÌûàÏä§ÌÜ†Î¶¨ ÏóÜÏùå"

        all_issues = []
        all_suggestions = []

        for iteration in recent_iterations:
            all_issues.extend(iteration.reflection_result.issues)
            all_suggestions.extend(iteration.reflection_result.suggestions)

        issue_counts = {}
        suggestion_counts = {}

        for issue in all_issues:
            issue_counts[issue] = issue_counts.get(issue, 0) + 1

        for suggestion in all_suggestions:
            suggestion_counts[suggestion] = suggestion_counts.get(suggestion, 0) + 1

        top_issues = sorted(issue_counts.items(), key=lambda x: x[1], reverse=True)[:3]
        top_suggestions = sorted(suggestion_counts.items(), key=lambda x: x[1], reverse=True)[:3]

        pattern_analysis = "Î∞òÎ≥µÎêòÎäî Ï£ºÏöî Ïù¥Ïäà:\n"
        for issue, count in top_issues:
            pattern_analysis += f"- {issue} (Î∞úÏÉù {count}Ìöå)\n"

        pattern_analysis += "\nÏûêÏ£º Ï†úÏïàÎêòÎäî Í∞úÏÑ†ÏÇ¨Ìï≠:\n"
        for suggestion, count in top_suggestions:
            pattern_analysis += f"- {suggestion} (Ï†úÏïà {count}Ìöå)\n"

        return pattern_analysis

    def _extract_reflection_from_text(self, text: str) -> Dict[str, Any]:
        """ÌÖçÏä§Ìä∏ÏóêÏÑú reflection Ï†ïÎ≥¥ Ï∂îÏ∂ú (JSON ÌååÏã± Ïã§Ìå® Ïãú Î∞±ÏóÖ)"""
        import re

        score_match = re.search(r'score["\s:]*(\d+\.?\d*)', text, re.IGNORECASE)
        score = float(score_match.group(1)) if score_match else 5.0

        return {
            "score": score,
            "overall_issues": ["ÌÖçÏä§Ìä∏ ÌååÏã±ÏúºÎ°ú Ï∂îÏ∂úÎêú Ïù¥Ïäà"],
            "improvement_suggestions": ["ÏÉÅÏÑ∏ Î∂ÑÏÑùÏùÑ ÏúÑÌï¥ JSON ÌòïÏãù ÏùëÎãµ ÌïÑÏöî"],
            "overall_assessment": "Î∂ÄÎ∂ÑÏ†Å ÌèâÍ∞Ä ÏôÑÎ£å"
        }

    def _is_code_modification_request(self, description: str) -> bool:
        """ÏΩîÎìú ÏàòÏ†ï ÏöîÏ≤≠Ïù∏ÏßÄ ÌåêÎã®"""
        modification_keywords = [
            "ÏàòÏ†ï", "Î≥ÄÍ≤Ω", "Î∞îÍøî", "Ï†úÍ±∞", "ÏÇ≠Ï†ú", "Ï∂îÍ∞ÄÌï¥Ï§ò", "Í≥†Ï≥ê",
            "Ï£ºÏÑù Ï†úÍ±∞", "Ï£ºÏÑù Ï∂îÍ∞Ä", "Î¶¨Ìå©ÌÜ†ÎßÅ", "ÏµúÏ†ÅÌôî",
            "Ïù¥ ÏΩîÎìúÎ•º", "Î∞©Í∏à ÎßåÎì†", "ÎÑàÍ∞Ä ÎßåÎì†", "Í∏∞Ï°¥ ÏΩîÎìú",
            "Ïù¥ Ïï±Ïóê", "Ïù¥ ÌîÑÎ°úÍ∑∏Îû®Ïóê", "ÏúÑ ÏΩîÎìúÏóê"
        ]

        description_lower = description.lower()
        return any(keyword in description_lower for keyword in modification_keywords)

    def _get_template_by_language(self, description: str, language: str, framework: Optional[str]) -> str:
        """Ïñ∏Ïñ¥Î≥Ñ ÌÖúÌîåÎ¶ø ÏÑ†ÌÉù"""
        templates = {
            "python": self._get_python_template(description, framework),
            "javascript": self._get_javascript_template(description, framework),
            "java": self._get_java_template(description, framework)
        }

        return templates.get(language, templates["python"])

    def _get_python_template(self, description: str, framework: Optional[str]) -> str:
        """Python ÏΩîÎìú ÏÉùÏÑ± ÌÖúÌîåÎ¶ø"""
        framework_info = ""
        if framework:
            framework_info = f"ÌîÑÎ†àÏûÑÏõåÌÅ¨Îäî {framework}ÏùÑ ÏÇ¨Ïö©Ìï¥Ï£ºÏÑ∏Ïöî."

        return f"""
                Îã§Ïùå ÏöîÍµ¨ÏÇ¨Ìï≠Ïóê ÎßûÎäî ÏôÑÏ†ÑÌïú Python ÏΩîÎìúÎ•º ÏûëÏÑ±Ìï¥Ï£ºÏÑ∏Ïöî:

                ÏöîÍµ¨ÏÇ¨Ìï≠: {description}
                {framework_info}
    
                Îã§Ïùå Ï°∞Í±¥ÏùÑ ÎßåÏ°±Ìï¥Ïïº Ìï©ÎãàÎã§:
                1. Î™®Îì† ÌïÑÏöîÌïú import Î¨∏ Ìè¨Ìï®
                2. Ïã§Ìñâ Í∞ÄÎä•Ìïú ÏôÑÏ†ÑÌïú ÏΩîÎìú
                3. ÏóêÎü¨ Ï≤òÎ¶¨ Ìè¨Ìï® (try-except)
                4. ÏÉÅÏÑ∏Ìïú Ï£ºÏÑùÏúºÎ°ú ÏΩîÎìú ÏÑ§Î™Ö
                5. Î©îÏù∏ Ïã§Ìñâ Î∂ÄÎ∂Ñ Ìè¨Ìï® (if __name__ == "__main__":)
                6. ÏÇ¨Ïö©Ïûê ÏπúÌôîÏ†ÅÏù∏ Ï∂úÎ†• Î©îÏãúÏßÄ

                ÏΩîÎìúÎßå Ï∂úÎ†•ÌïòÍ≥† Îã§Î•∏ ÏÑ§Î™ÖÏùÄ ÏµúÏÜåÌôîÌï¥Ï£ºÏÑ∏Ïöî.
                """

    def _get_javascript_template(self, description: str, framework: Optional[str]) -> str:
        """JavaScript ÏΩîÎìú ÏÉùÏÑ± ÌÖúÌîåÎ¶ø"""
        framework_info = ""
        if framework:
            framework_info = f"ÌîÑÎ†àÏûÑÏõåÌÅ¨Îäî {framework}ÏùÑ ÏÇ¨Ïö©Ìï¥Ï£ºÏÑ∏Ïöî."

        return f"""
            Îã§Ïùå ÏöîÍµ¨ÏÇ¨Ìï≠Ïóê ÎßûÎäî ÏôÑÏ†ÑÌïú JavaScript ÏΩîÎìúÎ•º ÏûëÏÑ±Ìï¥Ï£ºÏÑ∏Ïöî:

            ÏöîÍµ¨ÏÇ¨Ìï≠: {description}
            {framework_info}

            Îã§Ïùå Ï°∞Í±¥ÏùÑ ÎßåÏ°±Ìï¥Ïïº Ìï©ÎãàÎã§:
            1. Î™®Îì† ÌïÑÏöîÌïú import/require Î¨∏ Ìè¨Ìï®
            2. Ïã§Ìñâ Í∞ÄÎä•Ìïú ÏôÑÏ†ÑÌïú ÏΩîÎìú
            3. ÏóêÎü¨ Ï≤òÎ¶¨ Ìè¨Ìï® (try-catch)
            4. ÏÉÅÏÑ∏Ìïú Ï£ºÏÑùÏúºÎ°ú ÏΩîÎìú ÏÑ§Î™Ö
            5. ÏÇ¨Ïö©Ïûê ÏπúÌôîÏ†ÅÏù∏ Ï∂úÎ†•

            ÏΩîÎìúÎßå Ï∂úÎ†•ÌïòÍ≥† Îã§Î•∏ ÏÑ§Î™ÖÏùÄ ÏµúÏÜåÌôîÌï¥Ï£ºÏÑ∏Ïöî.
            """

    def _get_java_template(self, description: str, framework: Optional[str]) -> str:
        """Java ÏΩîÎìú ÏÉùÏÑ± ÌÖúÌîåÎ¶ø"""
        framework_info = ""
        if framework:
            framework_info = f"ÌîÑÎ†àÏûÑÏõåÌÅ¨Îäî {framework}ÏùÑ ÏÇ¨Ïö©Ìï¥Ï£ºÏÑ∏Ïöî."

        return f"""
            Îã§Ïùå ÏöîÍµ¨ÏÇ¨Ìï≠Ïóê ÎßûÎäî ÏôÑÏ†ÑÌïú Java ÏΩîÎìúÎ•º ÏûëÏÑ±Ìï¥Ï£ºÏÑ∏Ïöî:

            ÏöîÍµ¨ÏÇ¨Ìï≠: {description}
            {framework_info}

            Îã§Ïùå Ï°∞Í±¥ÏùÑ ÎßåÏ°±Ìï¥Ïïº Ìï©ÎãàÎã§:
            1. ÏôÑÏ†ÑÌïú ÌÅ¥ÎûòÏä§ Íµ¨Ï°∞
            2. Î™®Îì† ÌïÑÏöîÌïú import Î¨∏ Ìè¨Ìï®
            3. Ïã§Ìñâ Í∞ÄÎä•Ìïú main Î©îÏÜåÎìú
            4. ÏòàÏô∏ Ï≤òÎ¶¨ Ìè¨Ìï®
            5. ÏÉÅÏÑ∏Ìïú Ï£ºÏÑùÏúºÎ°ú ÏΩîÎìú ÏÑ§Î™Ö

            ÏΩîÎìúÎßå Ï∂úÎ†•ÌïòÍ≥† Îã§Î•∏ ÏÑ§Î™ÖÏùÄ ÏµúÏÜåÌôîÌï¥Ï£ºÏÑ∏Ïöî.
            """

    async def _should_perform_web_search(self, description: str, language: str, framework: Optional[str]) -> bool:
        """Ïõπ Í≤ÄÏÉâÏù¥ ÌïÑÏöîÌïúÏßÄ ÌåêÎã®"""
        if not self.enable_web_search:
            return False

        # Ïõπ Í≤ÄÏÉâÏù¥ ÌïÑÏöîÌïú ÌÇ§ÏõåÎìúÎì§
        web_search_keywords = [
            "ÏµúÏã†", "latest", "newest", "current", "2024", "2025",
            "ÏóÖÎç∞Ïù¥Ìä∏", "update", "Î≤ÑÏ†Ñ", "version",
            "ÏÉàÎ°úÏö¥", "new", "Ìä∏Î†åÎìú", "trend",
            "API", "ÎùºÏù¥Î∏åÎü¨Î¶¨", "library", "Ìå®ÌÇ§ÏßÄ", "package",
            "ÌîÑÎ†àÏûÑÏõåÌÅ¨", "framework", "ÎèÑÍµ¨", "tool",
            "ÏÑ§Ïπò", "install", "setup", "configuration",
            "ÏóêÎü¨", "error", "Î¨∏Ï†ú", "issue", "Ìï¥Í≤∞", "solution"
        ]

        description_lower = description.lower()

        # ÌÇ§ÏõåÎìú Í∏∞Î∞ò 1Ï∞® ÌåêÎã®
        keyword_score = sum(1 for keyword in web_search_keywords if keyword in description_lower)

        if keyword_score >= 2:
            return True

        # LLMÏùÑ Ïù¥Ïö©Ìïú Ï†ïÍµêÌïú ÌåêÎã®
        judgment_prompt = f"""
        Îã§Ïùå ÏΩîÎìú ÏÉùÏÑ± ÏöîÏ≤≠Ïóê ÎåÄÌï¥ Ïõπ Í≤ÄÏÉâÏù¥ ÌïÑÏöîÌïúÏßÄ ÌåêÎã®Ìï¥Ï£ºÏÑ∏Ïöî:

        ÏöîÏ≤≠: {description}
        Ïñ∏Ïñ¥: {language}
        ÌîÑÎ†àÏûÑÏõåÌÅ¨: {framework or "ÏóÜÏùå"}

        Ïõπ Í≤ÄÏÉâÏù¥ ÌïÑÏöîÌïú Í≤ΩÏö∞:
        - ÏµúÏã† Í∏∞Ïà†, ÎùºÏù¥Î∏åÎü¨Î¶¨, API Ï†ïÎ≥¥Í∞Ä ÌïÑÏöîÌïú Í≤ΩÏö∞
        - ÌäπÏ†ï ÏóêÎü¨ÎÇò Î¨∏Ï†ú Ìï¥Í≤∞Î≤ïÏù¥ ÌïÑÏöîÌïú Í≤ΩÏö∞
        - ÏÑ§Ïπò/ÏÑ§Ï†ï Î∞©Î≤ïÏù¥ ÌïÑÏöîÌïú Í≤ΩÏö∞
        - ÏóÖÎç∞Ïù¥Ìä∏Îêú Î¨∏Î≤ïÏù¥ÎÇò Î∞©Î≤ïÎ°†Ïù¥ ÌïÑÏöîÌïú Í≤ΩÏö∞

        0.0 (Î∂àÌïÑÏöî) ~ 1.0 (Îß§Ïö∞ ÌïÑÏöî) ÏÇ¨Ïù¥Ïùò Ï†êÏàòÎßå Ï∂úÎ†•ÌïòÏÑ∏Ïöî.
        """

        try:
            judgment_response = self.llm.invoke(judgment_prompt)
            score = float(judgment_response.strip())
            return score >= self.web_search_threshold
        except:
            return keyword_score >= 1

    async def _perform_web_search(self, keywords: List[str]) -> str:
        """Google Custom Search APIÎ•º ÏÇ¨Ïö©Ìïú Ïõπ Í≤ÄÏÉâ"""
        try:

            if not self.google_api_key or not self.search_engine_id:
                logger.error("Google Search API ÏÑ§Ï†ïÏù¥ ÏôÑÎ£åÎêòÏßÄ ÏïäÏïòÏäµÎãàÎã§.")
                return "Google Search API ÏÑ§Ï†ïÏù¥ ÏôÑÎ£åÎêòÏßÄ ÏïäÏïòÏäµÎãàÎã§."

            import aiohttp
            import urllib.parse

            # Í≤ÄÏÉâ ÏøºÎ¶¨ ÏµúÏ†ÅÌôî
            search_query = " ".join(keywords)
            encoded_query = urllib.parse.quote(search_query)

            # Google Custom Search API URL
            search_url = (
                f"https://www.googleapis.com/customsearch/v1"
                f"?key={self.google_api_key}"
                f"&cx={self.search_engine_id}"
                f"&q={encoded_query}"
                f"&num={min(self.max_search_results, 10)}"
            )

            logger.info(f"Í≤ÄÏÉâ URL: {search_url[:100]}...")  # API ÌÇ§ ÎÖ∏Ï∂ú Î∞©ÏßÄÎ•º ÏúÑÌï¥ Ï≤òÏùå 100Í∏ÄÏûêÎßå

            async with aiohttp.ClientSession() as session:
                async with session.get(search_url) as response:
                    logger.info(f"ÏùëÎãµ ÏÉÅÌÉú ÏΩîÎìú: {response.status}")

                    if response.status == 200:
                        data = await response.json()
                        logger.info(f"ÏùëÎãµ Îç∞Ïù¥ÌÑ∞ ÌÇ§: {list(data.keys())}")

                        # Í≤ÄÏÉâ Í≤∞Í≥º Ï≤òÎ¶¨
                        results = []
                        items = data.get('items', [])
                        logger.info(f"Í≤ÄÏÉâÎêú ÏïÑÏù¥ÌÖú Ïàò: {len(items)}")

                        if not items:
                            logger.warning("Í≤ÄÏÉâ Í≤∞Í≥ºÍ∞Ä ÎπÑÏñ¥ÏûàÏäµÎãàÎã§.")
                            logger.info(f"Ï†ÑÏ≤¥ ÏùëÎãµ Îç∞Ïù¥ÌÑ∞: {data}")
                            return "Í≤ÄÏÉâ Í≤∞Í≥ºÎ•º Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§."

                        for i, item in enumerate(items):
                            title = item.get('title', '')
                            snippet = item.get('snippet', '')
                            link = item.get('link', '')

                            logger.info(f"Í≤∞Í≥º {i + 1}: Ï†úÎ™©='{title[:50]}...', ÎßÅÌÅ¨='{link}'")

                            # Í≤∞Í≥º Ìè¨Îß∑ÌåÖ
                            result_text = f"**{title}**\n{snippet}"
                            if link:
                                result_text += f"\nüîó {link}"

                            results.append(result_text)

                        if results:
                            search_info = data.get('searchInformation', {})
                            total_results = search_info.get('totalResults', '0')
                            search_time = search_info.get('searchTime', '0')

                            logger.info(f"Í≤ÄÏÉâ ÏôÑÎ£å - Ï¥ù {len(results)}Í∞ú Í≤∞Í≥º Î∞òÌôò")

                            final_result = f"""
    üîç **Ïõπ Í≤ÄÏÉâ Í≤∞Í≥º** (Ï¥ù {total_results}Í∞ú Í≤∞Í≥º, {search_time}Ï¥à)

    {chr(10).join(f"{i + 1}. {result}" for i, result in enumerate(results))}
    """
                            logger.info(f"ÏµúÏ¢Ö Í≤∞Í≥º Í∏∏Ïù¥: {len(final_result)} Î¨∏Ïûê")
                            return final_result
                        else:
                            logger.warning("Í≤∞Í≥º Î¶¨Ïä§Ìä∏Í∞Ä ÎπÑÏñ¥ÏûàÏäµÎãàÎã§.")
                            return "Í≤ÄÏÉâ Í≤∞Í≥ºÎ•º Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§."

                    elif response.status == 403:
                        error_data = await response.json()
                        logger.error(f"403 ÏóêÎü¨: {error_data}")
                        error_message = error_data.get('error', {}).get('message', '')
                        if 'quota' in error_message.lower():
                            return "Google Search API Ìï†ÎãπÎüâÏù¥ Ï¥àÍ≥ºÎêòÏóàÏäµÎãàÎã§."
                        else:
                            return f"Google Search API Ï†ëÍ∑º Í∂åÌïú Ïò§Î•ò: {error_message}"

                    else:
                        response_text = await response.text()
                        logger.error(f"ÏòàÏÉÅÏπò Î™ªÌïú ÏùëÎãµ ÏÉÅÌÉú: {response.status}, ÎÇ¥Ïö©: {response_text[:200]}")
                        return f"Ïõπ Í≤ÄÏÉâ Ï§ë Ïò§Î•òÍ∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§. ÏÉÅÌÉú ÏΩîÎìú: {response.status}"

        except Exception as e:
            logger.error(f"Google Ïõπ Í≤ÄÏÉâ Ïã§Ìå®: {e}", exc_info=True)
            return f"Ïõπ Í≤ÄÏÉâÏùÑ ÏàòÌñâÌï† Ïàò ÏóÜÏäµÎãàÎã§: {str(e)}"

    def _get_optimized_query(self, description: str, language: str) -> List[str]:
        """LLMÏùÑ Ïù¥Ïö©Ìï¥ descriptionÏóêÏÑú Í≤ÄÏÉâ ÌÇ§ÏõåÎìú Ï∂îÏ∂ú"""
        try:
            description_optimized_query = f"""
    Îã§Ïùå ÏΩîÎìú ÏÉùÏÑ± ÏöîÏ≤≠ÏóêÏÑú Ïõπ Í≤ÄÏÉâÏóê ÌïÑÏöîÌïú ÌïµÏã¨ ÌÇ§ÏõåÎìúÎßå Ï∂îÏ∂úÌï¥Ï£ºÏÑ∏Ïöî.

    ÏöîÏ≤≠: {description}
    ÌîÑÎ°úÍ∑∏ÎûòÎ∞ç Ïñ∏Ïñ¥: {language}

    Í∑úÏπô:
    1. Í∏∞Ïà†Ï†Å Ïö©Ïñ¥ÏôÄ ÌïµÏã¨ Í∞úÎÖêÎßå Ìè¨Ìï®
    2. Î∂àÌïÑÏöîÌïú Ï°∞ÏÇ¨ÎÇò Î∂ÄÏÇ¨ Ï†úÍ±∞
    3. ÏòÅÏñ¥ Í∏∞Ïà† Ïö©Ïñ¥ Ïö∞ÏÑ† ÏÇ¨Ïö©
    4. ÏµúÎåÄ 5Í∞úÏùò ÌÇ§ÏõåÎìúÎßå ÏÑ†ÌÉù
    5. Í∞Å ÌÇ§ÏõåÎìúÎäî 1-3Îã®Ïñ¥Î°ú Íµ¨ÏÑ±
    6. Î∞òÎìúÏãú JSON Î∞∞Ïó¥ ÌòïÌÉúÎ°úÎßå ÏùëÎãµ: ["ÌÇ§ÏõåÎìú1", "ÌÇ§ÏõåÎìú2", "ÌÇ§ÏõåÎìú3"]

    ÏòàÏãú:
    - ÏöîÏ≤≠: "Spring BootÏóêÏÑú JWT ÌÜ†ÌÅ∞ Ïù∏Ï¶ùÏùÑ Íµ¨ÌòÑÌïòÎäî Î∞©Î≤ïÏùÑ ÏïåÎ†§Ï£ºÏÑ∏Ïöî"
    - ÏùëÎãµ: ["Spring Boot", "JWT", "authentication", "token", "security"]

    ÏùëÎãµ ÌòïÏãù: ["ÌÇ§ÏõåÎìú1", "ÌÇ§ÏõåÎìú2", ...]
    """

            # LLM Ìò∏Ï∂ú
            response = self.llm.invoke(description_optimized_query)
            logger.info(f"LLM ÌÇ§ÏõåÎìú Ï∂îÏ∂ú ÏùëÎãµ: {response}")

            # ÏùëÎãµÏóêÏÑú JSON Î∞∞Ïó¥ Ï∂îÏ∂ú
            keywords = self._parse_keywords_from_response(response)

            # Í∏∞Î≥∏ ÌÇ§ÏõåÎìú Ï∂îÍ∞Ä (Ïñ∏Ïñ¥Î™Ö)
            if language and language not in keywords:
                keywords.insert(0, language)

            logger.info(f"Ï∂îÏ∂úÎêú ÌÇ§ÏõåÎìú: {keywords}")
            return keywords[:5]  # ÏµúÎåÄ 5Í∞úÎ°ú Ï†úÌïú

        except Exception as e:
            logger.error(f"ÌÇ§ÏõåÎìú Ï∂îÏ∂ú Ïã§Ìå®: {e}")
            # Ïã§Ìå®Ïãú Í∏∞Î≥∏ ÌÇ§ÏõåÎìú Î∞òÌôò
            return self._get_fallback_keywords(description, language)

    def _parse_keywords_from_response(self, response: str) -> List[str]:
        """LLM ÏùëÎãµÏóêÏÑú ÌÇ§ÏõåÎìú Î∞∞Ïó¥ ÌååÏã±"""
        import json
        import re

        try:
            # 1Ï∞® ÏãúÎèÑ: ÏßÅÏ†ë JSON ÌååÏã±
            if response.strip().startswith('[') and response.strip().endswith(']'):
                return json.loads(response.strip())

            # 2Ï∞® ÏãúÎèÑ: JSON Î∞∞Ïó¥ Ìå®ÌÑ¥ Ï∞æÍ∏∞
            json_pattern = r'\[([^\]]+)\]'
            matches = re.findall(json_pattern, response)

            if matches:
                # Í∞ÄÏû• Í∏¥ Îß§ÏπòÎ•º ÏÑ†ÌÉù (Í∞ÄÏû• ÏôÑÏ†ÑÌïú Î∞∞Ïó¥Ïùº Í∞ÄÎä•ÏÑ±)
                json_str = f"[{max(matches, key=len)}]"
                return json.loads(json_str)

            # 3Ï∞® ÏãúÎèÑ: Îî∞Ïò¥ÌëúÎ°ú ÎëòÎü¨Ïã∏Ïù∏ Îã®Ïñ¥Îì§ Ï∂îÏ∂ú
            quoted_pattern = r'"([^"]+)"'
            keywords = re.findall(quoted_pattern, response)

            if keywords:
                return keywords

            # 4Ï∞® ÏãúÎèÑ: ÏâºÌëúÎ°ú Íµ¨Î∂ÑÎêú Îã®Ïñ¥Îì§ (Îî∞Ïò¥Ìëú Ï†úÍ±∞)
            if ',' in response:
                # Î∞∞Ïó¥ ÌëúÏãúÏûê Ï†úÍ±∞
                cleaned = re.sub(r'[\[\]"]', '', response)
                keywords = [kw.strip() for kw in cleaned.split(',') if kw.strip()]
                return keywords[:5]

            # 5Ï∞® ÏãúÎèÑ: Í≥µÎ∞±ÏúºÎ°ú Íµ¨Î∂ÑÎêú Ï§ëÏöîÌïú Îã®Ïñ¥Îì§
            words = response.split()
            # Í∏∏Ïù¥Í∞Ä 2Í∏ÄÏûê Ïù¥ÏÉÅÏù∏ Îã®Ïñ¥Îì§Îßå ÏÑ†ÌÉù
            keywords = [word.strip('.,[]"') for word in words if len(word.strip('.,[]"')) > 1]
            return keywords[:5]

        except Exception as e:
            logger.error(f"ÌÇ§ÏõåÎìú ÌååÏã± Ïã§Ìå®: {e}")
            return []

    def _get_fallback_keywords(self, description: str, language: str) -> List[str]:
        """LLM Ïã§Ìå®Ïãú Í∏∞Î≥∏ ÌÇ§ÏõåÎìú Ï∂îÏ∂ú"""
        import re

        keywords = []

        # Ïñ∏Ïñ¥ Ï∂îÍ∞Ä
        if language:
            keywords.append(language)

        # Í∏∞Ïà† Ïö©Ïñ¥ Ìå®ÌÑ¥ Ï∂îÏ∂ú
        tech_patterns = [
            r'\b[A-Z][a-z]*[A-Z][a-zA-Z]*\b',  # CamelCase (Spring Boot, JWT Îì±)
            r'\b[A-Z]{2,}\b',  # ÎåÄÎ¨∏Ïûê ÏïΩÏñ¥ (API, REST, JWT Îì±)
            r'\b\w+(?:\.js|\.py|\.java|\.go)\b',  # ÌååÏùº ÌôïÏû•Ïûê
        ]

        for pattern in tech_patterns:
            matches = re.findall(pattern, description)
            keywords.extend(matches)

        # ÏùºÎ∞òÏ†ÅÏù∏ ÌîÑÎ°úÍ∑∏ÎûòÎ∞ç ÌÇ§ÏõåÎìú
        common_terms = {
            'Ïù∏Ï¶ù': 'authentication',
            'ÌÜ†ÌÅ∞': 'token',
            'Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§': 'database',
            'ÏÑúÎ≤Ñ': 'server',
            'ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏': 'client',
            'ÌÖåÏä§Ìä∏': 'test',
            'Íµ¨ÌòÑ': 'implementation',
            'ÏòàÏ†ú': 'example',
        }

        for korean, english in common_terms.items():
            if korean in description:
                keywords.append(english)

        # Ï§ëÎ≥µ Ï†úÍ±∞ÌïòÍ≥† ÏµúÎåÄ 5Í∞ú
        unique_keywords = list(dict.fromkeys(keywords))  # ÏàúÏÑú Ïú†ÏßÄÌïòÎ©∞ Ï§ëÎ≥µ Ï†úÍ±∞
        return unique_keywords[:5]

    # Ìé∏Ïùò Î©îÏÑúÎìúÎì§
    def set_improvement_enabled(self, enabled: bool):
        """Self-improvement Í∏∞Îä• ÌôúÏÑ±Ìôî/ÎπÑÌôúÏÑ±Ìôî"""
        self.enable_self_improvement = enabled
        logger.info(f"Self-improvement Î™®Îìú: {'ÌôúÏÑ±Ìôî' if enabled else 'ÎπÑÌôúÏÑ±Ìôî'}")

    def set_quality_threshold(self, threshold: float):
        """ÌíàÏßà ÏûÑÍ≥ÑÍ∞í ÏÑ§Ï†ï (0-10)"""
        self.min_acceptable_score = max(0.0, min(10.0, threshold))
        logger.info(f"ÌíàÏßà ÏûÑÍ≥ÑÍ∞í ÏÑ§Ï†ï: {self.min_acceptable_score}")

    def set_max_iterations(self, max_iter: int):
        """ÏµúÎåÄ Î∞òÎ≥µ ÌöüÏàò ÏÑ§Ï†ï"""
        self.max_iterations = max(1, min(10, max_iter))
        logger.info(f"ÏµúÎåÄ Î∞òÎ≥µ ÌöüÏàò ÏÑ§Ï†ï: {self.max_iterations}")

    def get_improvement_history(self, session_id: str) -> List[ImprovementIteration]:
        """ÏÑ∏ÏÖòÎ≥Ñ Í∞úÏÑ† ÌûàÏä§ÌÜ†Î¶¨ Ï°∞Ìöå"""
        return self.improvement_history.get(session_id, [])

    def get_improvement_statistics(self, session_id: str) -> Dict[str, Any]:
        """Í∞úÏÑ† ÌÜµÍ≥Ñ Ï†ïÎ≥¥"""
        history = self.get_improvement_history(session_id)
        if not history:
            return {}

        total_iterations = len(history)
        avg_initial_score = sum(iter.reflection_result.score for iter in history) / total_iterations
        common_issues = {}

        for iteration in history:
            for issue in iteration.reflection_result.issues:
                common_issues[issue] = common_issues.get(issue, 0) + 1

        return {
            "total_requests": len(set(iter.timestamp // 3600 for iter in history)),
            "total_iterations": total_iterations,
            "average_initial_score": round(avg_initial_score, 1),
            "most_common_issues": sorted(common_issues.items(), key=lambda x: x[1], reverse=True)[:5],
            "improvement_rate": round((total_iterations - len(history)) / max(total_iterations, 1) * 100, 1)
        }


# Ïã±Í∏ÄÌÜ§ Ïù∏Ïä§ÌÑ¥Ïä§
ollama_service = OllamaService()
