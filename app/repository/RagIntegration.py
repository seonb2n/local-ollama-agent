import os

os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'
from typing import List, Optional, Dict, Any, Tuple
from txtai import Embeddings, RAG
import logging
import json

logger = logging.getLogger(__name__)


class RAGIntegration:
    """FastAPIì™€ LLMì„ ìœ„í•œ RAG í†µí•© í´ë˜ìŠ¤"""

    def __init__(self, embeddings_model: str = "sentence-transformers/all-MiniLM-L6-v2"):
        self.embeddings = None
        self.rag_pipeline = None
        self.embeddings_model = embeddings_model
        self.knowledge_base = []
        self.is_initialized = False

    async def initialize(self, ollama_model: str = "deepseek-coder-v2:16b-lite-instruct-q4_K_M"):
        """RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        try:
            # ì„ë² ë”© ë°ì´í„°ë² ì´ìŠ¤ë§Œ ì´ˆê¸°í™” (RAG íŒŒì´í”„ë¼ì¸ ì œê±°)
            self.embeddings = Embeddings(
                path=self.embeddings_model,
                content=True
            )

            # ê¸°ë³¸ í”„ë¡œê·¸ë˜ë° ì§€ì‹ ë² ì´ìŠ¤ ë¡œë“œ
            await self._load_programming_knowledge()

            # â­ï¸ RAG íŒŒì´í”„ë¼ì¸ ì œê±°, ìˆ˜ë™ìœ¼ë¡œ êµ¬í˜„
            self.ollama_model = ollama_model
            self.is_initialized = True
            logger.info("âœ… RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")

        except Exception as e:
            logger.error(f"âŒ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise

    async def search_knowledge(self, keyword: List[str], max_results: int = 3) -> str:
        """ì§€ì‹ ë² ì´ìŠ¤ì—ì„œ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰"""
        if not self.is_initialized:
            return ""

        try:
            # ë²¡í„° ê²€ìƒ‰ ìˆ˜í–‰
            optimized_query = " ".join(keyword)
            search_results = self.embeddings.search(optimized_query, max_results)

            if not search_results:
                # í‚¤ì›Œë“œ ê²€ìƒ‰ ì‹¤íŒ¨ ì‹œ ì›ë³¸ ì¿¼ë¦¬ë¡œ ì¬ì‹œë„
                logger.info("í‚¤ì›Œë“œ ê²€ìƒ‰ ì‹¤íŒ¨, ì›ë³¸ ì¿¼ë¦¬ë¡œ ì¬ì‹œë„")
                search_results = self.embeddings.search(keyword, max_results)

            return self._format_search_results(search_results)

        except Exception as e:
            logger.error(f"RAG ì§€ì‹ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return ""

    def _format_search_results(self, search_results) -> str:
        """ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì½ê¸° ì‰¬ìš´ í˜•íƒœë¡œ í¬ë§·íŒ…"""
        if not search_results:
            return ""

        formatted_results = []

        for i, result in enumerate(search_results):
            try:
                # txtai ê²€ìƒ‰ ê²°ê³¼ í˜•íƒœì— ë”°ë¼ ì²˜ë¦¬
                if isinstance(result, tuple):
                    # (id, score, text, metadata) ë˜ëŠ” (id, score) í˜•íƒœ
                    if len(result) >= 3:
                        doc_id, score, text = result[0], result[1], result[2]
                        metadata = result[3] if len(result) > 3 else {}
                    else:
                        doc_id, score = result[0], result[1]
                        text = f"ë¬¸ì„œ ID: {doc_id}"
                        metadata = {}

                elif isinstance(result, dict):
                    # dict í˜•íƒœ ê²°ê³¼
                    doc_id = result.get('id', f'doc_{i}')
                    score = result.get('score', 0.0)
                    text = result.get('text', result.get('content', 'No content available'))
                    metadata = result.get('metadata', {})

                else:
                    # ê¸°íƒ€ í˜•íƒœ - ë‹¨ìˆœ ë¬¸ìì—´ì´ë‚˜ ì˜ˆìƒì¹˜ ëª»í•œ í˜•íƒœ
                    doc_id = f'result_{i}'
                    score = 1.0 - (i * 0.1)  # ìˆœì„œ ê¸°ë°˜ ê°€ìƒ ì ìˆ˜
                    text = str(result)
                    metadata = {}

                # ë©”íƒ€ë°ì´í„°ì—ì„œ ì •ë³´ ì¶”ì¶œ
                topic = metadata.get('topic', 'general')
                level = metadata.get('level', 'intermediate')
                category = metadata.get('category', '')
                version = metadata.get('version', '')

                # ì œëª© ìƒì„±
                title_parts = [topic.upper()]
                if version:
                    title_parts.append(f"v{version}")
                if category:
                    title_parts.append(f"({category})")

                title = " ".join(title_parts)

                # í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ (ë„ˆë¬´ ê¸¸ë©´ ìë¥´ê¸°)
                max_text_length = 200
                if len(text) > max_text_length:
                    text = text[:max_text_length] + "..."

                # ê²°ê³¼ í¬ë§·íŒ…
                formatted_result = f"""
    {i + 1}. **{title}** [{level}]
      {text}
      ğŸ“Š ê´€ë ¨ë„: {score:.3f}
    """

                formatted_results.append(formatted_result)

            except Exception as e:
                logger.error(f"ê²€ìƒ‰ ê²°ê³¼ í¬ë§·íŒ… ì‹¤íŒ¨ (ê²°ê³¼ {i}): {e}")
                # ì—ëŸ¬ ë°œìƒ ì‹œ ê¸°ë³¸ í¬ë§·
                formatted_results.append(f"""
    {i + 1}. **ê²€ìƒ‰ ê²°ê³¼**
      {str(result)[:100]}...
      ğŸ“Š ê´€ë ¨ë„: 0.500
    """)

        return "\n".join(formatted_results)

    async def _load_programming_knowledge(self):
        """í”„ë¡œê·¸ë˜ë° ê´€ë ¨ ì§€ì‹ ë² ì´ìŠ¤ ë¡œë“œ (ë²¡í„° DB ì—°ë™)"""

        # ì§€ì†ì„± ìˆëŠ” ì„ë² ë”© ì €ì¥ì†Œ ì„¤ì •
        index_path = "./rag_data/programming_embeddings"

        try:
            # ê¸°ì¡´ ì¸ë±ìŠ¤ê°€ ìˆìœ¼ë©´ ë¡œë“œ
            if os.path.exists(index_path):
                logger.info("ğŸ“‚ ê¸°ì¡´ ì§€ì‹ ë² ì´ìŠ¤ ë¡œë“œ ì¤‘...")
                self.embeddings.load(index_path)
                logger.info("âœ… ê¸°ì¡´ ì§€ì‹ ë² ì´ìŠ¤ ë¡œë“œ ì™„ë£Œ")
                return

        except Exception as e:
            logger.warning(f"ê¸°ì¡´ ì¸ë±ìŠ¤ ë¡œë“œ ì‹¤íŒ¨, ìƒˆë¡œ ìƒì„±: {e}")

        # ìƒˆë¡œìš´ ì§€ì‹ ë² ì´ìŠ¤ ìƒì„±
        logger.info("ğŸ”„ ìƒˆë¡œìš´ ì§€ì‹ ë² ì´ìŠ¤ ìƒì„± ì¤‘...")

        programming_knowledge = [
            {
                "id": "java_24_late_barrier_expansion",
                "text": "Java 24ì˜ Late Barrier Expansion for G1ì€ G1 ê°€ë¹„ì§€ ì»¬ë ‰í„°ì˜ ì„±ëŠ¥ì„ ê°œì„ í•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤. ë©”ëª¨ë¦¬ ë°°ë¦¬ì–´ ì‚½ì…ì„ ëŸ°íƒ€ì„ê¹Œì§€ ì§€ì—°ì‹œì¼œ ì»´íŒŒì¼ ì‹œì ì˜ ìµœì í™” ê¸°íšŒë¥¼ ëŠ˜ë¦½ë‹ˆë‹¤. -XX:+UseLateBarrierExpansion í”Œë˜ê·¸ë¡œ í™œì„±í™”í•  ìˆ˜ ìˆìœ¼ë©°, ê³ ì„±ëŠ¥ ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ GC ì˜¤ë²„í—¤ë“œë¥¼ ì¤„ì´ëŠ” ë° íš¨ê³¼ì ì…ë‹ˆë‹¤.",
                "metadata": {"topic": "java", "level": "advanced", "version": "24"}
            },
            {
                "id": "java_gc_tuning",
                "text": "Java GC íŠœë‹ì„ ìœ„í•´ì„œëŠ” í™ ì‚¬ì´ì¦ˆ ì„¤ì •(-Xms, -Xmx), GC ì•Œê³ ë¦¬ì¦˜ ì„ íƒ(-XX:+UseG1GC, -XX:+UseZGC), GC ë¡œê¹…(-Xlog:gc), ê·¸ë¦¬ê³  ì• í”Œë¦¬ì¼€ì´ì…˜ë³„ ìµœì í™”ê°€ í•„ìš”í•©ë‹ˆë‹¤. G1GCì—ì„œëŠ” -XX:MaxGCPauseMillisë¡œ ëª©í‘œ ì¼ì‹œì •ì§€ ì‹œê°„ì„ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
                "metadata": {"topic": "java", "level": "advanced", "category": "performance"}
            },
            {
                "id": "java_jvm_monitoring",
                "text": "JVM ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ì„ ìœ„í•´ì„œëŠ” JProfiler, VisualVM, JConsole ë“±ì˜ ë„êµ¬ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. JFR(Java Flight Recorder)ë¥¼ í†µí•´ ì €ì˜¤ë²„í—¤ë“œë¡œ ì„±ëŠ¥ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê³ , jstat, jmap, jstack ëª…ë ¹ì–´ë¡œ ì‹¤ì‹œê°„ JVM ìƒíƒœë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
                "metadata": {"topic": "java", "level": "intermediate", "category": "monitoring"}
            },
            {
                "id": "java_memory_management",
                "text": "Java ë©”ëª¨ë¦¬ ê´€ë¦¬ì—ì„œ í™ì€ Young Generation(Eden, Survivor ê³µê°„)ê³¼ Old Generationìœ¼ë¡œ ë‚˜ë‰©ë‹ˆë‹¤. ê°ì²´ëŠ” Edenì—ì„œ ìƒì„±ë˜ì–´ GCë¥¼ ê±°ì³ Old Generationìœ¼ë¡œ ìŠ¹ê²©ë©ë‹ˆë‹¤. OutOfMemoryError í•´ê²°ì„ ìœ„í•´ì„œëŠ” í™ ë¤í”„ ë¶„ì„ê³¼ ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ì°¾ê¸°ê°€ ì¤‘ìš”í•©ë‹ˆë‹¤.",
                "metadata": {"topic": "java", "level": "intermediate", "category": "memory"}
            },
            {
                "id": "java_performance_testing",
                "text": "Java ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ì„œëŠ” JMH(Java Microbenchmark Harness)ë¥¼ ì‚¬ìš©í•˜ì—¬ ì •í™•í•œ ë²¤ì¹˜ë§ˆí¬ë¥¼ ì‘ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. @Benchmark ì–´ë…¸í…Œì´ì…˜ìœ¼ë¡œ í…ŒìŠ¤íŠ¸ ë©”ì„œë“œë¥¼ ì§€ì •í•˜ê³ , @BenchmarkModeë¡œ ì¸¡ì • ë°©ì‹ì„ ì„¤ì •í•©ë‹ˆë‹¤. Warmupê³¼ ì¸¡ì • ë°˜ë³µ íšŸìˆ˜ ì„¤ì •ì´ ì •í™•í•œ ê²°ê³¼ë¥¼ ìœ„í•´ ì¤‘ìš”í•©ë‹ˆë‹¤.",
                "metadata": {"topic": "java", "level": "advanced", "category": "testing"}
            },
            {
                "id": "java_latest_features",
                "text": "ìµœì‹  Java ë²„ì „ë“¤ì˜ ì£¼ìš” ê¸°ëŠ¥: Java 21 LTSì˜ Virtual Threads, Pattern Matching, Record Patterns; Java 22ì˜ Unnamed Variables, String Templates; Java 23ì˜ Primitive Types in Patterns; Java 24 Previewì˜ Late Barrier Expansion. --enable-preview í”Œë˜ê·¸ë¡œ ë¯¸ë¦¬ë³´ê¸° ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
                "metadata": {"topic": "java", "level": "advanced", "category": "features"}
            },
            {
                "id": "jvm_flags_optimization",
                "text": "JVM ìµœì í™”ë¥¼ ìœ„í•œ ì£¼ìš” í”Œë˜ê·¸ë“¤: -XX:+UseStringDeduplication (ë¬¸ìì—´ ì¤‘ë³µì œê±°), -XX:+UseCompressedOops (ì••ì¶• í¬ì¸í„°), -XX:+TieredCompilation (ê³„ì¸µ ì»´íŒŒì¼), -XX:ReservedCodeCacheSize (ì½”ë“œ ìºì‹œ í¬ê¸°), -XX:+UseNUMA (NUMA ìµœì í™”). í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œëŠ” ì¶©ë¶„í•œ í…ŒìŠ¤íŠ¸ í›„ ì ìš©í•´ì•¼ í•©ë‹ˆë‹¤.",
                "metadata": {"topic": "java", "level": "expert", "category": "optimization"}
            },
            {
                "id": "g1gc_configuration",
                "text": "G1GC ì„¤ì • ê°€ì´ë“œ: -XX:+UseG1GCë¡œ í™œì„±í™”, -XX:MaxGCPauseMillis=200ìœ¼ë¡œ ëª©í‘œ ì¼ì‹œì •ì§€ ì‹œê°„ ì„¤ì •, -XX:G1HeapRegionSizeë¡œ ë¦¬ì „ í¬ê¸° ì¡°ì •, -XX:G1NewSizePercentì™€ -XX:G1MaxNewSizePercentë¡œ Young Generation ë¹„ìœ¨ ì„¤ì •. ëŒ€ìš©ëŸ‰ í™(4GB ì´ìƒ)ì—ì„œ íš¨ê³¼ì ì…ë‹ˆë‹¤.",
                "metadata": {"topic": "java", "level": "advanced", "category": "gc"}
            }
        ]

        # â­ï¸ í•µì‹¬ ìˆ˜ì •: ë©”íƒ€ë°ì´í„°ë¥¼ JSON ë¬¸ìì—´ë¡œ ë³€í™˜
        processed_data = []
        for item in programming_knowledge:
            if item.get("text"):  # ë¹ˆ í•­ëª© ì œì™¸
                metadata = item.get("metadata", {})
                # dictë¥¼ JSON ë¬¸ìì—´ë¡œ ë³€í™˜
                metadata_json = json.dumps(metadata) if metadata else None

                processed_data.append((
                    item["id"],
                    item["text"],
                    metadata_json  # JSON ë¬¸ìì—´ë¡œ ì „ë‹¬
                ))

        # ì„ë² ë”© ì¸ë±ìŠ¤ ìƒì„± ë° ë””ìŠ¤í¬ì— ì €ì¥
        self.embeddings.index(processed_data)

        # ë²¡í„° DBì— ì§€ì†ì ìœ¼ë¡œ ì €ì¥
        os.makedirs(os.path.dirname(index_path), exist_ok=True)
        self.embeddings.save(index_path)

        logger.info(f"ğŸ’¾ ì§€ì‹ ë² ì´ìŠ¤ ìƒì„± ë° ì €ì¥ ì™„ë£Œ: {len(processed_data)}ê°œ ë¬¸ì„œ")

    async def _fetch_additional_knowledge(self) -> List[dict]:
        """ì¶”ê°€ ì§€ì‹ì„ ì›¹ì—ì„œ ìˆ˜ì§‘ (ì„ íƒì‚¬í•­)"""
        additional_docs = []

        # ì—¬ê¸°ì— ì›¹ í¬ë¡¤ë§ì´ë‚˜ API í˜¸ì¶œ ë¡œì§ ì¶”ê°€ ê°€ëŠ¥
        # ì˜ˆ: Python ê³µì‹ ë¬¸ì„œ, FastAPI ë¬¸ì„œ ë“±

        return additional_docs

    async def should_use_rag(self, query: str) -> bool:
        """RAG ì‚¬ìš© ì—¬ë¶€ íŒë‹¨"""
        # í”„ë¡œê·¸ë˜ë° ê´€ë ¨ í‚¤ì›Œë“œ í™•ì¸
        programming_keywords = [
            "python", "fastapi", "docker", "async", "await", "api", "í•¨ìˆ˜", "í´ë˜ìŠ¤",
            "ë¼ì´ë¸ŒëŸ¬ë¦¬", "ì„¤ì¹˜", "ì‚¬ìš©ë²•", "ì˜ˆì œ", "ì½”ë“œ", "ì˜¤ë¥˜", "ì—ëŸ¬", "í•´ê²°",
            "ìµœì í™”", "ì„±ëŠ¥", "êµ¬í˜„", "ë°©ë²•", "how to", "ì‚¬ìš©ë°©ë²•"
        ]

        query_lower = query.lower()
        keyword_found = any(keyword in query_lower for keyword in programming_keywords)

        # ì§ˆë¬¸ í˜•íƒœì¸ì§€ í™•ì¸
        question_indicators = ["?", "ì–´ë–»ê²Œ", "ë¬´ì—‡", "ì™œ", "ì–¸ì œ", "ì–´ë””ì„œ", "how", "what", "why", "when"]
        is_question = any(indicator in query_lower for indicator in question_indicators)

        return keyword_found or is_question

    async def get_rag_response(self, query: str) -> str:
        """RAGë¥¼ ì‚¬ìš©í•˜ì—¬ ì‘ë‹µ ìƒì„±"""
        if not self.is_initialized:
            raise Exception("RAG ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        try:
            # RAG íŒŒì´í”„ë¼ì¸ì„ í†µí•´ ì‘ë‹µ ìƒì„±
            response = self.rag_pipeline(query)
            return response

        except Exception as e:
            logger.error(f"RAG ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {e}")
            return f"RAG ì‹œìŠ¤í…œì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

    async def add_document(self, text: str, metadata: dict = None):
        """ìƒˆ ë¬¸ì„œë¥¼ ì§€ì‹ ë² ì´ìŠ¤ì— ì¶”ê°€"""
        if not self.is_initialized:
            return

        try:
            doc_id = f"custom_{len(self.knowledge_base)}"
            self.knowledge_base.append({"id": doc_id, "text": text, "metadata": metadata or {}})

            # ê¸°ì¡´ ì¸ë±ìŠ¤ì— ë¬¸ì„œ ì¶”ê°€ (upsert)
            self.embeddings.upsert([(doc_id, text, metadata or {})])

            logger.info(f"ğŸ“„ ìƒˆ ë¬¸ì„œ ì¶”ê°€ë¨: {doc_id}")

        except Exception as e:
            logger.error(f"ë¬¸ì„œ ì¶”ê°€ ì‹¤íŒ¨: {e}")
